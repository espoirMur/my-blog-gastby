<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Espoir Murhabazi ideas' home</title>
    <description>Murhabazi Buzina Espoir Home on the internet</description>
    <link>http://localhost:4000/</link>
    <atom:link href="http://localhost:4000/feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Mon, 04 Nov 2024 13:32:39 +0000</pubDate>
    <lastBuildDate>Mon, 04 Nov 2024 13:32:39 +0000</lastBuildDate>
    <generator>Jekyll v4.2.2</generator>
    
      <item>
        <title>Guide to Exploring Kahuzi-Biega National Park: Gorilla Trekking and Adventures in South Kivu, DRC</title>
        <description>&lt;p&gt;Last December, I had a chance to visit the Kahuzi-Biega National Park in South Kivu. 
I grew up in Bukavu and spent most of my adulthood there but I have never had a chance to visit that park yet it was just a few kilometers from home.&lt;/p&gt;

&lt;p&gt;It is only when I moved abroad that I find the need to visit our national treasure.&lt;/p&gt;

&lt;p&gt;We planned a family trip with my siblings and cousins and decided to visit the mountain gorillas.
When I posted the visit pictures online lot of people reached out to me asking for more information on how to visit the park. That is the reason why I decided to write this post. I will highlight the steps I took to see the park, hopefully, those who want to visit the park in the future will find this post useful.&lt;/p&gt;

&lt;figure&gt;
  &lt;p&gt;&lt;img src=&quot;/assets/posts/2024-10-16-visit-kahuzi-biega/mountain-gorilla.jpeg&quot; /&gt;&lt;/p&gt;
  &lt;figcaption&gt;Mountain Gorilla, the King of the Park&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;So you want to visit le Parc National de Kahuzi Biega where to start?&lt;/p&gt;

&lt;h2 id=&quot;a-brief-info-about-the-parc&quot;&gt;A brief info about the Parc.&lt;/h2&gt;

&lt;p&gt;The Kahuzi-Biega National Park (PNKB) was gazetted in 1970 to conserve the Grauer’s gorilla, the world’s largest gorilla species. It remains the only place in the world where visitors can see these gorillas in the wild. The park covers an area of 6000 km2 and protects a mountain forest in eastern DRC, which is the most densely populated region of the country. The park is named after the two spectacular extinct volcanoes that dominate its high-altitude sector, Mont Kahuzi (3,308m) and Mont Biega (2,790m).&lt;/p&gt;

&lt;p&gt;The park is located in the South Kivu province in East DRC. It is a few kilometers from the &lt;strong&gt;Ruzizi Borders between DRC and Rwanda&lt;/strong&gt;.&lt;/p&gt;

&lt;figure&gt;
  &lt;p&gt;&lt;img src=&quot;/assets/posts/2024-10-16-visit-kahuzi-biega/parc-kahuzi-map.png&quot; /&gt;&lt;/p&gt;
  &lt;figcaption&gt;How close the park is to Rwanda&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;h2 id=&quot;is-it-safe-to-go-there&quot;&gt;Is it safe to go there?&lt;/h2&gt;

&lt;p&gt;Currently,  there is an ongoing rebellion in the North Kivu region, the region around Goma the twin province to Bukavu. However, Bukavu is quite safe to visit.&lt;/p&gt;

&lt;p&gt;But things change quickly in the region, you can check this &lt;a href=&quot;https://radiomaendeleo.net/&quot;&gt;local website&lt;/a&gt; for more information about what is going on in the region.&lt;/p&gt;

&lt;h1 id=&quot;how-to-get-to-bukavu&quot;&gt;How to get to Bukavu&lt;/h1&gt;
&lt;p&gt;In this section, I will write about the visa, how to get flights to Bukavu and how to get to the Park.&lt;/p&gt;

&lt;figure&gt;
  &lt;p&gt;&lt;img src=&quot;/assets/posts/2024-10-16-visit-kahuzi-biega/rdc-border.png&quot; /&gt;&lt;/p&gt;
  &lt;figcaption&gt;Welcome to Congo 🇨🇩&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;h2 id=&quot;the-visa&quot;&gt;The visa&lt;/h2&gt;

&lt;p&gt;Our country is not well organized, we don’t have a working system for e-visa like other countries in the world or in Africa.(Actually, it seems like you can apply for an e-visa to visit Congo. check the section bellow.) We don’t also have a visa on Arrival for foreigners unless you know someone in Congo who can get an invitation for you. Check option B for more info.&lt;/p&gt;

&lt;h3 id=&quot;the-official-way&quot;&gt;The official way.&lt;/h3&gt;

&lt;p&gt;The first way to apply for a Congolese visa is to go to the nearest Congolese embassy in your region and submit your visa application from there. We have embassies in &lt;a href=&quot;https://www.ambardc.london/d/&quot;&gt;UK&lt;/a&gt;, US, Canada, &lt;a href=&quot;https://www.ambardcparis.com/vec_beta.php&quot;&gt;and France&lt;/a&gt;, and major countries in the world. Please check out with the nearest Congolese embassy in your region to find out about the procedure to get a Congolese visa.
The last time I checked the DRC embassy in France, they said that it is 85 euros for a single entry and &lt;strong&gt;115 Euros&lt;/strong&gt; for multiple entries for one month.
For those in the UK it says, &lt;strong&gt;£ 135 for 1 month multiple entries&lt;/strong&gt;, and it can goes up to £ 350 for six months multiple entries. More about that and the procedure can be found &lt;a href=&quot;https://forms.ambardc.london/&quot;&gt;at he london embassy official site.&lt;/a&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Pro tip: Congo is a very corrupt country, and this is not something we are proud of. When you go to an official office and ask for the visa, after paying the official visa fees, you can add some extra fees (transport, or tips ) to the official who registered your application to speed up the application process. It is sometimes called transport buying a drink for the person who processes your application.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;the-second-option&quot;&gt;The second option.&lt;/h3&gt;
&lt;p&gt;The second way is to use an invitation from a Congolese national.
A friend of mine told me if you have an invitation from a Congolese national, he can get you an invitation for 60 USD at the migration office and with that invitation, you can apply for a visa on arrival at the Congolese border.
With this option, I need to double-check, as I don’t know who have used it before.&lt;/p&gt;

&lt;h3 id=&quot;the-third-option&quot;&gt;The third option.&lt;/h3&gt;

&lt;p&gt;The third way is to use the &lt;a href=&quot;https://evisa.gouv.cd/&quot;&gt;e-visa&lt;/a&gt; system. Yes, we have an e-visa system but I have never checked or used it. 
I need to document more about this &lt;a href=&quot;https://evisa.gouv.cd/helps/faqs&quot;&gt;option&lt;/a&gt; but it seems to be well documented.&lt;/p&gt;

&lt;p&gt;In their FAQ, they said anyone who wants a Tourist visa to Congo can apply via the website. I have never tested it, please give it a try and let me know if it works. The site said that it cost 300 USD for the visa.&lt;/p&gt;

&lt;h3 id=&quot;fourth-option&quot;&gt;Fourth option.&lt;/h3&gt;

&lt;p&gt;If you have Congolese origins, you were either born in Congo, or your parents were born in Congo, you can apply for a visa on arrival. It costs around 100 USD for multiple entries for a month.&lt;/p&gt;

&lt;p&gt;You can also read more about visas &lt;a href=&quot;https://www.aeroport-kinshasa.com/en/visa_on_arrival_congo.php#:~:text=In%20accordance%20with%20laws%20and,down%20by%20laws%20and%20regulations.&quot;&gt;here:&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;fifth-option&quot;&gt;Fifth Option.&lt;/h3&gt;

&lt;p&gt;There seems to be like there is a tourist visa offered by the parc. On their &lt;a href=&quot;https://www.kahuzibiega.org/plan-your-trip/visa/&quot;&gt;website&lt;/a&gt;, they said that they can help you to get a visa on arrival. If you book directly via the parc website,  they can give you an invitation letter to show on arrival and help you to get a tourist visa to visit the park for 14 days. But please double check with the parc if this option is still there. 
Once you got the invitation, this become the same as the second option.&lt;/p&gt;

&lt;h2 id=&quot;flights&quot;&gt;Flights&lt;/h2&gt;

&lt;figure&gt;
  &lt;p&gt;&lt;img src=&quot;/assets/posts/2024-10-16-visit-kahuzi-biega/bateau-emanuel.png&quot; /&gt;&lt;/p&gt;
  &lt;figcaption&gt;The beauty of Lake Kivu.&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;Congo is a huge country, it is almost as huge as the EU. 
You can’t travel to the Capital city Kinshasa which is in the Ouest, and drive to the Kivu region in the East because there are no roads. Local flights are expensive, sometimes more expensive than traveling from Congo to Europe or Congo to the Middle East.&lt;/p&gt;

&lt;p&gt;As you can see on the map in the cover picture of this post, Bukavu can be covered by two Airports international airports. The Aeroport International de Goma, and the Kigali International Airport.
However, it is easier and cheaper to use Kigali airport if you want to travel to Bukavu.&lt;/p&gt;

&lt;p&gt;Kigali is in Rwanda and the Airport is served by major airlines such as Rwandair, KenyaAirways, Qatar Airways, AirFrance, etc.&lt;/p&gt;

&lt;p&gt;In off-season periods, flights from major cities in Europe such as Brussels, Paris, and Amsterdam to Kigali are operated by either Rwandair, Kenya Airways, Air France, or Brussels Airlines and cost around 500-700 USD.&lt;/p&gt;

&lt;p&gt;From Kigali Airport, you can usually take a 20-minute local flight to Kamembe which is a small town near the Congo - Rwanda Border.  This flight cost around 100 USD return tickets and they are operated by Rwandair.&lt;/p&gt;

&lt;p&gt;If you want to be more adventurous, you can take a bus from Kigali to Gisenyi, visit Gisenyi town, then cross the Congo-Rwanda border in Gisenyi and reach Congo via Goma.&lt;/p&gt;

&lt;p&gt;From Goma, you can take a boat via Lake Kivu and reach Bukavu via the Beach. Those boats cost from 20 USD to 50 USD depending on the type of boat you take.&lt;/p&gt;

&lt;h2 id=&quot;where-to-stay-in-bukavu&quot;&gt;Where to stay in Bukavu?&lt;/h2&gt;

&lt;figure&gt;
  &lt;p&gt;&lt;img src=&quot;/assets/posts/2024-10-16-visit-kahuzi-biega/lake-kivu.jpeg&quot; /&gt;&lt;/p&gt;
  &lt;figcaption&gt;Lake kivu&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;Once in Bukavu, you can stay in any hotel you want in BK.  My favorite ones are Nediva, hotel La Roche, and Coco Lodge, or Orchid Safari Club. I don’t want to promote hotels here, you can check them by yourself. There are also Airbnbs running in the town.&lt;/p&gt;

&lt;h2 id=&quot;how-do-we-go-to-the-parc&quot;&gt;How do we go to the Parc?&lt;/h2&gt;

&lt;p&gt;From Bukavu, you can hire a car by yourself and drive to the Parc. However, I would recommend having a local guide who will help you navigate the city and the way to the park.&lt;/p&gt;

&lt;p&gt;The park is located 30 km from Bukavu, with the quality of the road it can take 1h30 minutes in the rainy season and 1 hour in the dry season.&lt;/p&gt;

&lt;p&gt;A car rental can cost up to 100$ for the day, and the guide can charge you a negotiable fee to show you around.&lt;/p&gt;

&lt;p&gt;If you decide to get there by yourself, once you reach the park you can find local guides there.&lt;/p&gt;

&lt;h2 id=&quot;how-much-does-it-cost-to-visit-the-park&quot;&gt;How much does it cost to visit the park?&lt;/h2&gt;

&lt;p&gt;It costs foreigners &lt;strong&gt;400 USD&lt;/strong&gt; to visit the parc as per the last documentation. For local, and african from SADEC and East Africa Community countries it cost less than that. Don’t let anyone foul you or scam you by asking more than that amount to visit the park. A travel agent may ask you for their fees, but there is no fixed amount for that and it can be negotiable. There is a saying in Bukavu that says : &lt;code class=&quot;language-bash highlighter-rouge&quot;&gt;haba katalake franka&lt;/code&gt;. We don’t say no to money. You can use that to bargain with a guide when discussing his fees.&lt;/p&gt;

&lt;h2 id=&quot;how-much-does-it-cost-to-visit-the-gorilla&quot;&gt;How much does it cost to visit the Gorilla?&lt;/h2&gt;

&lt;p&gt;I have spoken about the major points here. Let summarize how much does it cost to visit he Gorilla in Park National de Kahuzi-Biega.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Flight ticket: Depends on your origin country.&lt;/li&gt;
  &lt;li&gt;Local flight from Kigali to Kamembe: 100 USD.&lt;/li&gt;
  &lt;li&gt;Visa: 100 USD if you apply from your country or 300 USD for e-visa.&lt;/li&gt;
  &lt;li&gt;Hotel in Bukavu: 100 USD to 200 USD for two days.&lt;/li&gt;
  &lt;li&gt;Car hire: 100 USD.&lt;/li&gt;
  &lt;li&gt;Parc visit: 400 USD&lt;/li&gt;
  &lt;li&gt;Guide: This is negotiable but let’s say 100 USD.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Assuming you have reached Kigali airport and you got your e-visa it will cost you approximately 1200 USD to visit les gorilles de montages de Bukavu, and the cost of your flight to Kigali.&lt;/p&gt;

&lt;p&gt;That is all for this post. I hope I have given you most of the information you need to visit the park. 
If you have any question or comment, please don’t hesitate to contact me.&lt;/p&gt;

&lt;h2 id=&quot;references&quot;&gt;References:&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://www.kahuzibiega.org/getting-there/&quot;&gt;Official Site&lt;/a&gt;: This is not the official website of the Park National de Kahuzi-Biega, but it provides useful information about the park.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://www.kahuzibieganationalpark.com/&quot;&gt;Tour Operator&lt;/a&gt;: Tour operator making buisness out of the Parc. Not affiliated with the Park.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.aeroport-kinshasa.com/en/visa_on_arrival_congo.php&quot;&gt;Kivu Airport&lt;/a&gt;:  Where I got information about visa on Arrival.&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://evisa.gouv.cd/&quot;&gt;e-visa&lt;/a&gt;: Yes, we have an e-visa now, I haven’t tried it thought.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://www.kahuzibieganationalparkcongo.org/&quot;&gt;A rwandan website&lt;/a&gt;: This site is not affiliated with the parc, they are doing buisness from Rwanda.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://en.wikivoyage.org/wiki/Kahuzi-Bi%C3%A9ga_National_Park&quot;&gt;Wikivoyage Page on the Parc&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.facebook.com/kahuzibiega.org/?profile_tab_item_selected=about&amp;amp;_rdr&quot;&gt;Pack official Facebook Page&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;-&lt;a href=&quot;https://thetravelersbuddy.com/kahuzi-biega-congo/&quot;&gt;Another Travel Blog About the parc&lt;/a&gt;&lt;/p&gt;
</description>
        <pubDate>Wed, 16 Oct 2024 13:53:10 +0100</pubDate>
        <link>http://localhost:4000/visit-kahuzi-biega</link>
        <guid isPermaLink="true">http://localhost:4000/visit-kahuzi-biega</guid>
        
        
      </item>
    
      <item>
        <title>Mounting Oracle Cloud Storage as Volume in Containers with Kubernetes.</title>
        <description>
&lt;figure&gt;
  &lt;p&gt;&lt;img src=&quot;/assets/posts/2024-06-19-mounting-oracle-cloud-storage-as-volume-in-containers-with-kubernetes/containers-in-ship.png&quot; /&gt;&lt;/p&gt;
  &lt;figcaption&gt;Containers in Ship&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;In my attempt to deploy a Machine Learning model with Kubernetes, I need to find a way to mount files hosted on Oracle Cloud Storage bucket to a docker container via Docker Volumes and later to Kubernetes using Kubernetes Volumes.&lt;/p&gt;

&lt;p&gt;I looked up online and couldn’t find a post that fit my needs hence why I decided to write this guide to highlight my approach and learnings.&lt;/p&gt;

&lt;p&gt;In this post, you will learn how to mount data in Oracle Cloud Storage or any other cloud object storage to a docker container and Kubernetes pods via Volumes. It is the second post of a series of posts that I am writing on deploying machine learning models on Kubernetes.  &lt;a href=&quot;https://www.murhabazi.com/deploying-language-model-with-onnx-runtime-on-triton-inference-server&quot;&gt;In the first post&lt;/a&gt;, we learned how to use the ONNX runtime, and the triton inference server to deploy our model as a docker container. However, in that post, we saw the need to use a model registry to save our model files.&lt;/p&gt;

&lt;p&gt;You will best benefit from this post if you already have some Docker containers and Kubernetes components knowledge. As for the prerequisites,  I suggest that you have Docker and Kubernetes installed on your machine.  Additionally, you need access to a Kubernetes cluster either via Minikube (local access) or via a cloud provider. In my case, I am using Oracle Cloud.&lt;/p&gt;

&lt;p&gt;I have used a cloud storage bucket as my model repository and hosted my machine learning model in it, making this post a more Machine Learning oriented one. Having said that, web developers can use the same approach illustrated in this post to share web static files such as CSS, and images.&lt;/p&gt;

&lt;p&gt;Let start by defining what is the Object Storage.&lt;/p&gt;

&lt;h2 id=&quot;what-is-object-storage&quot;&gt;&lt;center&gt;What is Object Storage?&lt;/center&gt;&lt;/h2&gt;

&lt;p&gt;An  Object Storage is a data storage architecture for storing unstructured data.It sections the data into units—objects and stores them in a structurally flat data environment. Each object includes the data, metadata, and a unique identifier that applications can use for easy access and retrieval. &lt;a href=&quot;https://cloud.google.com/learn/what-is-object-storage&quot;&gt;Source&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;With Object Storage, the data blocks of a file are kept together as objects, with a custom identifier and relevant metadata about them.
This type of storage architecture is well suited for unstructured data such as video,  music, and email which is written once and read multiple times.&lt;/p&gt;

&lt;p&gt;It is different from File Storage, where data is organized as files, and folders as files in real life. It is also different from Block Storage which is a performance improvement of file storage where files are broken into separate blocks and stored separately.&lt;/p&gt;

&lt;p&gt;Many cloud storage providers have stores that implement object storage architecture. In that storage, files are saved in buckets. The most common type of object store is Amazon Simple Storage Service (S3). Then comes Google Cloud Storage(GCS). Oracle Cloud, the storage we will be using in this post is one of the other S3 and GCS alternatives. You can check other S3 alternatives &lt;a href=&quot;https://github.com/s3fs-fuse/s3fs-fuse/wiki/Non-Amazon-S3&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;That being said, we can confirm that everything you can do on Amazon S3 can be replicated on other cloud provider object storage.&lt;/p&gt;

&lt;p&gt;Now that we know more about object storage , the next concept to grasp is Volumes.&lt;/p&gt;

&lt;h2 id=&quot;what-are-docker-and-kubernetes-volumes&quot;&gt;What are Docker and Kubernetes Volumes?&lt;/h2&gt;

&lt;h3 id=&quot;docker-volumes&quot;&gt;Docker Volumes.&lt;/h3&gt;

&lt;figure&gt;
  &lt;p&gt;&lt;img src=&quot;/assets/posts/2024-06-19-mounting-oracle-cloud-storage-as-volume-in-containers-with-kubernetes/docker-volumes.png&quot; /&gt;&lt;/p&gt;
  &lt;figcaption&gt;Docker Volumes&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;Docker containers are stateless components,  at the end of their lifecycle their contents are destroyed. All the data generated by a container and saved inside are deleted on its destruction. Volumes are handy when it comes to sharing data with a container, and to persisting data generated by a container. 
The most common use cases of docker volumes that I can think of on top of my head in Web Development are :&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Sharing static files with web application&lt;/li&gt;
  &lt;li&gt;Persisting data generated by a database container.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;In Machine Learning however, docker volumes mostly share model files with a deployment container, or sharing model training files with a training script.&lt;/p&gt;

&lt;p&gt;You can read more about docker volumes &lt;a href=&quot;https://docs.docker.com/storage/volumes/&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&quot;kubernetes-volumes&quot;&gt;Kubernetes Volumes.&lt;/h3&gt;

&lt;p&gt;Kubernetes volumes are similar to docker volumes. They can be seen as directory containing data accessible by multiple containers in a pod.
On top of sharing data and persisting data with a pod, Kubernetes volumes help to share data between containers in the same pod.&lt;/p&gt;

&lt;p&gt;Kubernetes offers different types of volumes, you can read more about them &lt;a href=&quot;https://kubernetes.io/docs/concepts/storage/volumes/&quot;&gt;here&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;In this post, we will be interested in two types of them, the &lt;code class=&quot;language-bash highlighter-rouge&quot;&gt;hostPath&lt;/code&gt; and &lt;code class=&quot;language-bash highlighter-rouge&quot;&gt;PersitantVolume&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;A &lt;code class=&quot;language-bash highlighter-rouge&quot;&gt;hostPath&lt;/code&gt; volume mounts a file or directory from the host node’s filesystem into your Pod. This type of volume is not recommended for production-grade applications because it presents many security risks. It is recommended to use &lt;code class=&quot;language-bash highlighter-rouge&quot;&gt;PersistantVolume&lt;/code&gt; and &lt;code class=&quot;language-bash highlighter-rouge&quot;&gt;PersistantVolumeClaim&lt;/code&gt; instead.&lt;/p&gt;

&lt;p&gt;Enough theory, let us write code.&lt;/p&gt;

&lt;h2 id=&quot;our-architecture&quot;&gt;Our Architecture.&lt;/h2&gt;

&lt;figure&gt;
  &lt;p&gt;&lt;img src=&quot;/assets/posts/2024-06-19-mounting-oracle-cloud-storage-as-volume-in-containers-with-kubernetes/architecture-diagram.png&quot; /&gt;&lt;/p&gt;
  &lt;figcaption&gt;Architecture Diagram.&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;In the figure above, we have the architecture diagram of what we are we will be deploying in this post.&lt;/p&gt;

&lt;p&gt;For our model container need to access models files, that are are in our registry.&lt;/p&gt;

&lt;h2 id=&quot;mounting-object-storage-bucket-in-a-docker-container&quot;&gt;Mounting Object Storage Bucket in a docker container.&lt;/h2&gt;

&lt;p&gt;We will be using the &lt;a href=&quot;https://github.com/s3fs-fuse/s3fs-fuse&quot;&gt;s3fs library&lt;/a&gt;, which is a tool that allows Unix/FreeBSD OS to mount object storage buckets via FUSE(Filesystem in UserSpace). It helps us to operate files and directories in an S3 bucket like a local file system.&lt;/p&gt;

&lt;p&gt;You can install it in any Unix system and mount the bucket path to your local machine.&lt;/p&gt;

&lt;p&gt;For our use case, we will install it and use it in a docker container.&lt;/p&gt;

&lt;h3 id=&quot;first-step--create-the-script&quot;&gt;First Step : Create the Script.&lt;/h3&gt;

&lt;p&gt;To mount our bucket we will use the following script, let name it &lt;code class=&quot;language-bash highlighter-rouge&quot;&gt;run.sh&lt;/code&gt;:&lt;/p&gt;

&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$ACCESS_KEY_ID&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$ORACLE_CLOUD_SECRET&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; passwd &lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;chmod &lt;/span&gt;600 passwd

&lt;span class=&quot;nv&quot;&gt;URL&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;https://&lt;span class=&quot;nv&quot;&gt;$TENANT_ID&lt;/span&gt;.compat.objectstorage.&lt;span class=&quot;nv&quot;&gt;$REGION&lt;/span&gt;.oraclecloud.com

s3fs &lt;span class=&quot;nt&quot;&gt;-f&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-d&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;$OCI_BUCKET&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;$MOUNT_POINT&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-o&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;endpoint&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$REGION&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-o&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;passwd_file&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;passwd &lt;span class=&quot;nt&quot;&gt;-o&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;url&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$URL&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-o&lt;/span&gt; nomultipart &lt;span class=&quot;nt&quot;&gt;-o&lt;/span&gt; use_path_request_style
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Our script expects the following environment variables to work.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;language-bash highlighter-rouge&quot;&gt;ACCESS_KEY_ID: &lt;/code&gt;: The access key ID&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-bash highlighter-rouge&quot;&gt;ORACLE_CLOUD_SECRET&lt;/code&gt;: The secret key
Those two are credential pairs from Oracle Cloud. You can grab them from your profile on Oracle Cloud. In case you are using another cloud provider, refer to the documentation to grab those credentials.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-bash highlighter-rouge&quot;&gt;TENANT_ID&lt;/code&gt;: Your Oracle Cloud tenant ID. is the unique identifier of your Oracle Cloud account.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-bash highlighter-rouge&quot;&gt;REGION&lt;/code&gt;: The region where your bucket is located.
With the tenant ID and the region, we can build the bucket format. Oracle cloud storage uses the following URL format: &lt;code class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;span class=&quot;nv&quot;&gt;URL&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;https://&lt;span class=&quot;nv&quot;&gt;$TENANT_ID&lt;/span&gt;.compat.objectstorage.&lt;span class=&quot;nv&quot;&gt;$REGION&lt;/span&gt;.oraclecloud.com&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;If you are using a different cloud provider than S3 or OracleCloud, check out &lt;a href=&quot;https://github.com/s3fs-fuse/s3fs-fuse/wiki/Non-Amazon-S3&quot;&gt;this guide&lt;/a&gt;, it illustrates how to define the URL to access the content of your bucket. 
You can also check the respective cloud provider documentation.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;language-bash highlighter-rouge&quot;&gt;OCI_BUCKET&lt;/code&gt;: Is the bucket name&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-bash highlighter-rouge&quot;&gt;MOUNT_POINT&lt;/code&gt;: This is the path where we are mounting our files in the container.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The command creates a file called &lt;code class=&quot;language-bash highlighter-rouge&quot;&gt;passwd&lt;/code&gt; and they put the credentials inside it. Then they change the permission of the file. Permission 600 means read and write from the owner and no other permission from the group and others.&lt;/p&gt;

&lt;p&gt;The main command  &lt;code class=&quot;language-bash highlighter-rouge&quot;&gt;s3fs&lt;/code&gt; mounts the bucket to the mount point. 
The flags &lt;code class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;span class=&quot;nt&quot;&gt;-f&lt;/span&gt;&lt;/code&gt; and &lt;code class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;span class=&quot;nt&quot;&gt;-d&lt;/span&gt;&lt;/code&gt; are for debugging purposes.&lt;/p&gt;

&lt;p&gt;Let us create a docker container that uses that script.&lt;/p&gt;

&lt;h3 id=&quot;second-step--build-the-container-image&quot;&gt;Second Step : Build the container image.&lt;/h3&gt;

&lt;p&gt;Let us create the docker image using the following DockerFile:&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;FROM anujkosambi/s3fs-fuse

ENV MOUNT_POINT /var/s3
RUN &lt;span class=&quot;nb&quot;&gt;mkdir&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-p&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;$MOUNT_POINT&lt;/span&gt;
COPY run.sh run.sh
RUN &lt;span class=&quot;nb&quot;&gt;chmod&lt;/span&gt; +x run.sh
CMD ./run.sh
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The docker container pulls from the &lt;code class=&quot;language-bash highlighter-rouge&quot;&gt;s3fs-fuse&lt;/code&gt; image and copies the &lt;code class=&quot;language-bash highlighter-rouge&quot;&gt;run.sh script&lt;/code&gt;, changes it permission to be executable, and then executes the script.&lt;/p&gt;

&lt;p&gt;If you have the docker file saved as &lt;code class=&quot;language-bash highlighter-rouge&quot;&gt;DockerFile&lt;/code&gt; and your &lt;code class=&quot;language-bash highlighter-rouge&quot;&gt;run&lt;/code&gt; script saved as &lt;code class=&quot;language-bash highlighter-rouge&quot;&gt;run.sh&lt;/code&gt; at the same location you can build your container using:&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;language-bash highlighter-rouge&quot;&gt;docker build &lt;span class=&quot;nt&quot;&gt;-t&lt;/span&gt; espymur/s3fs:latest &lt;span class=&quot;nt&quot;&gt;-f&lt;/span&gt; DockerFile &lt;span class=&quot;nb&quot;&gt;.&lt;/span&gt; &lt;/code&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;h3 id=&quot;third-step-starting-the-docker-container&quot;&gt;Third Step: Starting the docker container.&lt;/h3&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;In order run the container you need the values of your environment variables. Go to your cloud console and collect the environment variables. Then run the following command:&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;language-bash highlighter-rouge&quot;&gt;docker run  &lt;span class=&quot;nt&quot;&gt;--privileged&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-i&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-e&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;ORACLE_CLOUD_SECRET&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;your_secret &lt;span class=&quot;nt&quot;&gt;-e&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;OCI_BUCKET&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;bucket_name  &lt;span class=&quot;nt&quot;&gt;-e&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;REGION&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;your-region &lt;span class=&quot;nt&quot;&gt;-e&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;TENANT_ID&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;your_tenant-id &lt;span class=&quot;nt&quot;&gt;-e&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;ACCESS_KEY_ID&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;acces_key_id espymur/s3fs:latest&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;Note the &lt;code class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;span class=&quot;nt&quot;&gt;--privileged&lt;/span&gt;&lt;/code&gt; mode. It permits the docker container to write to the container host. You can read more about it &lt;a href=&quot;https://stackoverflow.com/questions/75296630/what-does-the-docker-exec-privileged-flag-do&quot;&gt;here&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;If everything is fine you should be able to exec a command in your container like this to check if the data in your bucket are there.&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;language-bash highlighter-rouge&quot;&gt;docker &lt;span class=&quot;nb&quot;&gt;exec&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-it&lt;/span&gt; container_id &lt;span class=&quot;nb&quot;&gt;ls&lt;/span&gt; /var/s3&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;The command should put the content of your bucket.&lt;/p&gt;

&lt;p&gt;Now we can mount the bucket content in our docker container, let us see how to use that in a Kubernetes environment.&lt;/p&gt;

&lt;p&gt;With we have achieved what we can see in the following image:&lt;/p&gt;

&lt;figure&gt;
  &lt;p&gt;&lt;img src=&quot;/assets/posts/2024-06-19-mounting-oracle-cloud-storage-as-volume-in-containers-with-kubernetes/storage-container.png&quot; /&gt;&lt;/p&gt;
  &lt;figcaption&gt;S3 storage mounted inside a docker container&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;h2 id=&quot;then-comes-kubernetes&quot;&gt;Then comes Kubernetes.&lt;/h2&gt;

&lt;p&gt;Now that the bucket mounts as in your docker container, let’s see how it would work in practice with Kubernetes.&lt;/p&gt;

&lt;p&gt;Our end goal is to deploy a Machine Learning model in a Kubernetes cluster. The bucket will act as our model repository, and It will host our Machine Learning model.&lt;/p&gt;

&lt;p&gt;The first component we will create is a &lt;code class=&quot;language-bash highlighter-rouge&quot;&gt;Secret&lt;/code&gt;, then we will create a &lt;code class=&quot;language-bash highlighter-rouge&quot;&gt;DaemontSet&lt;/code&gt;.&lt;/p&gt;

&lt;h3 id=&quot;kubernetes-secrets&quot;&gt;Kubernetes Secrets.&lt;/h3&gt;

&lt;blockquote&gt;
  &lt;p&gt;A Secret is an object that contains a small amount of sensitive data such as a password, a token, or a key. Such information might otherwise be put in a &lt;a href=&quot;https://kubernetes.io/docs/concepts/workloads/pods/&quot;&gt;Pod&lt;/a&gt; specification or in a &lt;a href=&quot;https://kubernetes.io/docs/reference/glossary/?all=true#term-image&quot;&gt;container image&lt;/a&gt;. Using a Secret means that you don’t need to include confidential data in your application code.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;For our usecase our secret are the Oracle cloud credentials. Please note that kubernetes secret should not be shared with git. We need to add the it path to &lt;code class=&quot;language-bash highlighter-rouge&quot;&gt;.gitignore&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;Here is how we will defines our kubernetes secrets:&lt;/p&gt;

&lt;div class=&quot;language-yaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;na&quot;&gt;apiVersion&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;v1&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;kind&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;Secret&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;metadata&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;oracle-cloud-credentials&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;Opaque&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;ORACLE_CLOUD_SECRET&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;secrets&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;hashed&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;in&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;base64=&quot;&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;OCI_BUCKET&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Your&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;hashed&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;in&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;base64=&quot;&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;REGION &lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;region&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;hashed&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;in&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;base64=&quot;&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;TENANT_ID&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;tenant&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;id&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;hashed&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;in&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;base64&quot;&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;ACCESS_KEY_ID&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;access&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;key&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;hashed&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;in&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;base64&quot;&lt;/span&gt;

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Note that the values in our secrets are the real values of our secrets hashed in base64. Using the following command.&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-n&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'oursecret'&lt;/span&gt; | &lt;span class=&quot;nb&quot;&gt;base64&lt;/span&gt;&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;We create the secrets with &lt;code class=&quot;language-bash highlighter-rouge&quot;&gt;kubectl apply &lt;span class=&quot;nt&quot;&gt;-f&lt;/span&gt; secret.yaml&lt;/code&gt;&lt;/p&gt;

&lt;h3 id=&quot;daemonset-component&quot;&gt;DaemonSet Component.&lt;/h3&gt;

&lt;blockquote&gt;
  &lt;p&gt;A &lt;em&gt;DaemonSet&lt;/em&gt; ensures that all (or some) Nodes run a copy of a Pod. As nodes are added to the cluster, Pods are added to them. As nodes are removed from the cluster, those Pods are garbage collected. Deleting a DaemonSet will clean up the Pods it created.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;A DaemonSet is the perfect component for our use case, we want to mount our bucket in all the nodes of our Kubernetes cluster in order to make the storage available to all pods that are running on the node.&lt;/p&gt;

&lt;p&gt;The DaemontSet will help us to achieve what we can view on this picture:&lt;/p&gt;

&lt;figure&gt;
  &lt;p&gt;&lt;img src=&quot;/assets/posts/2024-06-19-mounting-oracle-cloud-storage-as-volume-in-containers-with-kubernetes/daemonset.png&quot; /&gt;&lt;/p&gt;
  &lt;figcaption&gt;What our DaemontSet Achieve&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;I came across this component type when I was researching this tutorial.&lt;/p&gt;

&lt;p&gt;Here is how we create the DaemonSet:&lt;/p&gt;

&lt;div class=&quot;language-yaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;na&quot;&gt;apiVersion&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;apps/v1&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;kind&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;DaemonSet&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;metadata&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;k8s-app&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;oracle-cloud-provider&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;oracle-cloud-provider&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;spec&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;selector&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;matchLabels&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;oracle-cloud-provider&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;template&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;metadata&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;oracle-cloud-provider&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;spec&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;containers&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;oracle-cloud-fuse&lt;/span&gt;
          &lt;span class=&quot;na&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;  &lt;span class=&quot;s&quot;&gt;uk-london-1.ocir.io/lrtfqsmony6u/s3fs:latest&lt;/span&gt;
          &lt;span class=&quot;na&quot;&gt;imagePullPolicy&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;Always&lt;/span&gt;
          &lt;span class=&quot;na&quot;&gt;securityContext&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;na&quot;&gt;privileged&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;true&lt;/span&gt;
          &lt;span class=&quot;na&quot;&gt;envFrom&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;secretRef&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
                &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;oracle-cloud-credentials&lt;/span&gt;
          &lt;span class=&quot;na&quot;&gt;volumeMounts&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;devfuse&lt;/span&gt;
              &lt;span class=&quot;na&quot;&gt;mountPath&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;/dev/fuse&lt;/span&gt;
            &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;oracle-cloud-fs&lt;/span&gt;
              &lt;span class=&quot;na&quot;&gt;mountPath&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;/var/s3&lt;/span&gt;
              &lt;span class=&quot;na&quot;&gt;mountPropagation&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Bidirectional&quot;&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# this was the key to make it work.&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;volumes&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;devfuse&lt;/span&gt;
          &lt;span class=&quot;na&quot;&gt;hostPath&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;na&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;/dev/fuse&lt;/span&gt;
        &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;oracle-cloud-fs&lt;/span&gt;
          &lt;span class=&quot;na&quot;&gt;hostPath&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;na&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;/tmp/s3&lt;/span&gt;

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;As you can see the Daemonset syntax is familiar to the Deployment syntax, they both define pods and volumes.&lt;/p&gt;

&lt;p&gt;This Daemonset defines the container, this is the container we defined previously and it runs the s3fs code that mounts the bucket. You can check, we are running it with SecurityContext &lt;code class=&quot;language-bash highlighter-rouge&quot;&gt;privileged&lt;/code&gt; which is the equivalent of the docker mode &lt;code class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;span class=&quot;nt&quot;&gt;--privileged&lt;/span&gt;&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;The &lt;code class=&quot;language-bash highlighter-rouge&quot;&gt;VolumeMounts&lt;/code&gt; argument defines the original path of the content  (files ) we want to mount in &lt;strong&gt;our container&lt;/strong&gt;.&lt;br /&gt;
The &lt;code class=&quot;language-bash highlighter-rouge&quot;&gt;Volume&lt;/code&gt; definition, on the other hand, defines the volume mount path in the host system, for this case our Kubernetes nodes.&lt;/p&gt;

&lt;p&gt;This means that the content of the &lt;code class=&quot;language-bash highlighter-rouge&quot;&gt;/var/s3&lt;/code&gt; folder in our container will be mounted to the &lt;code class=&quot;language-bash highlighter-rouge&quot;&gt;/tmp/s3&lt;/code&gt; folder in our docker container. The hostPath argument needs to be a writeable folder in our docker container.&lt;/p&gt;

&lt;p&gt;The &lt;code class=&quot;language-bash highlighter-rouge&quot;&gt;mount propagation&lt;/code&gt; argument is important to make the mapping work, I spent hours trying to figure out this parameter to make my mount work.&lt;/p&gt;

&lt;p&gt;From the &lt;a href=&quot;https://kubernetes.io/docs/concepts/storage/volumes/#mount-propagation&quot;&gt;Kubernetes documentation&lt;/a&gt; we can read that:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;language-bash highlighter-rouge&quot;&gt;HostToContainer&lt;/code&gt; - This volume mount will receive all subsequent mounts that are mounted to this volume or any of its subdirectories.&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;In other words, if the host mounts anything inside the volume mount, the container will see it mounted there.&lt;/p&gt;

    &lt;p&gt;Similarly, if any Pod with &lt;code class=&quot;language-bash highlighter-rouge&quot;&gt;Bidirectional&lt;/code&gt; mount propagation to the same volume mounts anything there, the container with &lt;code class=&quot;language-bash highlighter-rouge&quot;&gt;HostToContainer&lt;/code&gt; mount propagation will see it.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code class=&quot;language-bash highlighter-rouge&quot;&gt;Bidirectional&lt;/code&gt; - This volume mount behaves the same the &lt;code class=&quot;language-bash highlighter-rouge&quot;&gt;HostToContainer&lt;/code&gt; mount. In addition, all volume mounts created by the container will be propagated back to the host and to all containers of all pods that use the same volume.&lt;/p&gt;

    &lt;p&gt;#### Warning:&lt;/p&gt;

    &lt;p&gt;&lt;code class=&quot;language-bash highlighter-rouge&quot;&gt;Bidirectional&lt;/code&gt; mount propagation can be dangerous. It can damage the host operating system and therefore it is allowed only in privileged containers. Familiarity with Linux kernel behavior is strongly recommended. In addition, any volume mounts created by containers in pods must be destroyed (unmounted) by the containers on termination.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;PS: I had some issues dealing with the container termination. If the Dameonset is not terminated properly the volume path will not work in the subsequent run. You have to change the path when you run it again to make it work.
We will create our Daemonset with&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;language-bash highlighter-rouge&quot;&gt;kubectl apply &lt;span class=&quot;nt&quot;&gt;-f&lt;/span&gt; daemonset.yaml&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;The Daemonset will create a pod in each node of our cluster, you can check the pods with&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;language-bash highlighter-rouge&quot;&gt;kubectl get pods&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;You will see the pod running.&lt;/p&gt;

&lt;p&gt;To check if the mount is working, you can ssh into your nodes and list the content of &lt;code class=&quot;language-bash highlighter-rouge&quot;&gt;/tmp/s3&lt;/code&gt;. Should everything works correctly, you should be able to see the content of the bucket.&lt;/p&gt;

&lt;p&gt;If not check the logs our your pod to see what went wrong.&lt;/p&gt;

&lt;p&gt;To ssh nodes in the cluster, you can use this &lt;a href=&quot;https://github.com/luksa/kubectl-plugins&quot;&gt;kubernetes plugin&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;If the Daemonset is working, go to the next step which is using it with the deployment to deploy models.&lt;/p&gt;

&lt;p&gt;I have read that using a docker container with &lt;code class=&quot;language-bash highlighter-rouge&quot;&gt;privileged &lt;/code&gt; mode offers security risk and may not be advised in a high-security environment. If that is your use case you can try to use Persisent Volume to achieve the same results.&lt;/p&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;To summarise, this posts has shown us how to mount the content of Object Storage like S3 in docker volume.  We leverage the &lt;code class=&quot;language-bash highlighter-rouge&quot;&gt;s3fs&lt;/code&gt; library and we mounted the strorage inside container. Finally, we used a Daemonset pod to share the content of our container with the nodes in our Kubernetes cluster.&lt;/p&gt;

&lt;p&gt;To know how this is done, go ahead and read part 3 of these series of posts where I will show how to deploy Machine Learning model using the created volume.&lt;/p&gt;

&lt;p&gt;In the next post, we will learn how to use that volume in a Machine Learning application.&lt;/p&gt;

&lt;h2 id=&quot;references&quot;&gt;References&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://dev.to/otomato_io/mount-s3-objects-to-kubernetes-pods-12f5&quot;&gt;Mount S3 Objects to Kubernetes Pods.&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://blog.meain.io/2020/mounting-s3-bucket-kube/&quot;&gt;Mounting S3 bucket in docker containers on kubernetes.&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Wed, 19 Jun 2024 14:20:27 +0100</pubDate>
        <link>http://localhost:4000/mounting-oracle-cloud-storage-as-volume-in-containers-with-kubernetes</link>
        <guid isPermaLink="true">http://localhost:4000/mounting-oracle-cloud-storage-as-volume-in-containers-with-kubernetes</guid>
        
        
      </item>
    
      <item>
        <title>Deploy your language models to production using ONNX runtime and the Triton inference server</title>
        <description>
&lt;figure&gt;
  &lt;p&gt;&lt;img src=&quot;/assets/posts/2024-04-07-deploying-language-model-with-onnx-runtime-on-triton-inference-server/cover-picture.png&quot; /&gt;&lt;/p&gt;
  &lt;figcaption&gt;Lac Kivu in East DRC&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;You are a Data Scientist who has finally trained a language model and it works in a jupyter notebook and you are happy with your results. Now you want to expose it to the users so that they can interact with it.&lt;/p&gt;

&lt;p&gt;You have different options to serve your model to your users. You can use the jupyter notebook directly in production 🤣. You can wrap the model in a pickle file and serve it using an API 🤪. Both options work, but can they handle millions of requests per second in a production environment? In this post, I will show how you can use modern tools to deploy a language model in a scalable way.  We will use the ONNX runtime, Triton inference server, Docker and Kubernetes. These tools will help us to deploy  a production-ready language model.&lt;/p&gt;

&lt;p&gt;This guide is addressed to Data scientists, Machine Learning Engineers and researchers aiming to use their Language Models in Production. It discusses the engineering principles of scalable language models APIs.&lt;/p&gt;

&lt;p&gt;It will be divided into multiple parts. In the first part, we will prepare the model for a production setting. We will use the ONNX runtime and Docker container to achieve that goal. Finally, in the second part, we will learn how to scale our Apis using Kubernetes.&lt;/p&gt;

&lt;p&gt;If I have time later, I’ll explain how to use the embedding API in a  downstream app  like a Retrieval Augmentation Generation (RAG).&lt;/p&gt;

&lt;p&gt;Before we dive into the deployment bits of this application, let us first review some theory about language models.&lt;/p&gt;

&lt;p&gt;We will be deploying an embedding model, so let start by defining a language model.&lt;/p&gt;

&lt;figure&gt;
  &lt;p&gt;&lt;img src=&quot;/assets/posts/2024-04-07-deploying-language-model-with-onnx-runtime-on-triton-inference-server/gorilla.png&quot; /&gt;&lt;/p&gt;
  &lt;figcaption&gt;Mountain Gorilla, one our similar cousin.&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;h2 id=&quot;embeddings&quot;&gt;Embeddings.&lt;/h2&gt;

&lt;p&gt;Embedding models are the backbone of generative AI, they are representations of words in a vector space. They capture words semantics such as, with them similar vectors represent similar words.&lt;/p&gt;

&lt;p&gt;Contextual embeddings are embeddings such as each word is represented with a vector given its context.&lt;/p&gt;

&lt;p&gt;Let’s look at those two examples:&lt;/p&gt;

&lt;p&gt;&lt;em&gt;The bank of the river Thames is located in South London.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;I am going to withdraw cash at Lloyds Bank.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;In those two sentences the word &lt;code class=&quot;language-bash highlighter-rouge&quot;&gt;bank&lt;/code&gt; has two different meanings. In the first, bank means &lt;em&gt;the land alongside or sloping down to a river or lake.&lt;/em&gt; In the second sentence, it means &lt;em&gt;a place where you save money.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Embedding models can capture those differences and represent words with two different vectors according to the context.&lt;/p&gt;

&lt;p&gt;This is not a post to explain how embedding models are built, if you want to learn more about them refer to &lt;a href=&quot;https://mccormickml.com/2019/05/14/BERT-word-embeddings-tutorial/&quot;&gt;this post.&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;But one thing to know is that embedding models are built with language models or Large language models for the majority of cases.&lt;/p&gt;

&lt;figure&gt;
  &lt;p&gt;&lt;img src=&quot;/assets/posts/2024-04-07-deploying-language-model-with-onnx-runtime-on-triton-inference-server/word-embeddings-representation.webp&quot; /&gt;&lt;/p&gt;
  &lt;figcaption&gt;Words Representation in 2D vector Space.&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;h2 id=&quot;large-language-model&quot;&gt;Large Language Model.&lt;/h2&gt;

&lt;p&gt;Large language models are neural networks or probabilistic models that can predict the next word given the previous words.&lt;/p&gt;

&lt;p&gt;One of the most common neural network architectures that power language models is the Transformer model. It was introduced in 2017 by Google researchers. Those models have a powerful capacity when it comes to understanding words and their meanings because they are trained on a large corpus of documents.&lt;/p&gt;

&lt;p&gt;During their training, transformers’ models can learn contextual word embeddings.  Those embeddings are useful in downstream applications such as chatbots, documents classification, topic modeling, documents clustering  et consort.&lt;/p&gt;

&lt;p&gt;Again, this post is not about language models, there  are legions on the internet, my favorite one is the  &lt;a href=&quot;https://jalammar.github.io/illustrated-transformer/&quot;&gt;illustrated trasnfomer&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;If this post is not about word embedding theory, or large language model theory what is it about?&lt;/p&gt;

&lt;p&gt;Nice question, this post is about deploying a large language model. We assume taht you have a model trained on you want to deploy it. We will learn how to create an embedding service, a api that developers can query to generate document embeddings.&lt;/p&gt;

&lt;p&gt;We will build a scalable API developers can query it to get word embeddings of their sentences. They can use the embeddings in downstream applications. This API can be part of a chatbot, or a Retrieval Augmented Generation application.&lt;/p&gt;

&lt;p&gt;I made it for educational purposes while learning how to deploy a language model using Kubernetes.  If you want a production-ready application that can support multiple embedding models  &lt;a href=&quot;https://github.com/jina-ai/clip-as-service&quot;&gt;checkout this repository.&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Enough talking let’s show us the code!&lt;/p&gt;

&lt;h2 id=&quot;the-embedding-models&quot;&gt;The embedding models.&lt;/h2&gt;

&lt;p&gt;In this post, we will explore the embedding model generated by the BioLinkBert. The BioLinkBert model is a model from the BERT family but it was fine-tuned on documents from the medical domain. The reason I used the Biolink model is that I wanted to build a chatbot application for the medical domain in the future.&lt;/p&gt;

&lt;p&gt;The embedding of words is the last hidden state of a transformer model where the input is the word encoded as text. Let us see how it works  in practice. We will be using a custom Bert model which inherits the base Bert model from Huggingface.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;torch&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;dataclasses&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dataclass&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;typing&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Optional&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Mapping&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;OrderedDict&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;transformers.onnx&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;OnnxConfig&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;transformers.utils&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ModelOutput&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;transformers&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;BertModel&lt;/span&gt;

&lt;span class=&quot;o&quot;&gt;@&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dataclass&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;EmbeddingOutput&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ModelOutput&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;last_hidden_state&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Optional&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;FloatTensor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;


&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;CustomEmbeddingBertModel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;BertModel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;forward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;input_ids&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Optional&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Tensor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;attention_mask&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Optional&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Tensor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;head_mask&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Optional&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Tensor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;inputs_embeds&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Optional&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Tensor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;EmbeddingOutput&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;embeddings&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;super&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;forward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;input_ids&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;input_ids&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                                     &lt;span class=&quot;n&quot;&gt;attention_mask&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;attention_mask&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                                     &lt;span class=&quot;n&quot;&gt;head_mask&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;head_mask&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                                     &lt;span class=&quot;n&quot;&gt;inputs_embeds&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;inputs_embeds&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                                     &lt;span class=&quot;n&quot;&gt;output_attentions&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                                     &lt;span class=&quot;n&quot;&gt;output_hidden_states&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                                     &lt;span class=&quot;n&quot;&gt;return_dict&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;mean_embedding&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;embeddings&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;last_hidden_state&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dim&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;embedding_output&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;EmbeddingOutput&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;last_hidden_state&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mean_embedding&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;embedding_output&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Our custom embedding is  a wrapper around the Bert embedding model. It  which take the input ids and return the embedding of a sentence. The input ids are the tokenized version of a sentence. The embeddings of the sentence are the average of the embedding of all words in a  sentence.&lt;/p&gt;

&lt;p&gt;Here is how that work in practice.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;embedding_model_id&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'michiyasunaga/BioLinkBERT-large'&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;base_model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;CustomEmbeddingBertModel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;from_pretrained&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;embedding_model_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Before passing the text to the embedding, it needs to be transformed in a tokenizer.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;transformers&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;AutoTokenizer&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;tokenizer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;AutoTokenizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;from_pretrained&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;embedding_model_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;


&lt;span class=&quot;n&quot;&gt;test_input&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;what is the cause of Covid&quot;&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;encoded_input&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tokenizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test_input&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
                          &lt;span class=&quot;n&quot;&gt;return_tensors&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'pt'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                          &lt;span class=&quot;n&quot;&gt;max_length&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;512&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                          &lt;span class=&quot;n&quot;&gt;truncation&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;With our encoded_input and the base model we can generate the text embedding for our text input.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;encoded_input&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;encoded_input&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pop&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'token_type_ids'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;embedding_output&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;base_model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;encoded_input&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;text_embeddings&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;embedding_output&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;last_hidden_state&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;detach&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;numpy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reshape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;text_embeddings&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The text embedding is the embedding representation of the sentence in text_input.
It can be use in downstream application in different ways.&lt;/p&gt;

&lt;p&gt;The next step is save the model in the format we can use to deploy it in production.&lt;/p&gt;

&lt;h2 id=&quot;exporting-the-model-to-onnx-format&quot;&gt;Exporting the Model to Onnx format.&lt;/h2&gt;

&lt;h3 id=&quot;what-is-the-onnx-format&quot;&gt;What is the ONNX format?&lt;/h3&gt;

&lt;p&gt;ONNX stands for Open Neural Network Exchange. It is an open format built to represent machine learning models in a framework and language-agnostic way.&lt;/p&gt;

&lt;p&gt;As you may know, neural networks are computation graphs with input, weights, and operations. ONNX format is a way of saving neural networks as computation graphs. That  computational graph represents the flow of data through the neural network.&lt;/p&gt;

&lt;p&gt;The key benefits of saving neural networks in the ONNX format are interoperability and hardware access. Any deep learning platform can read a neural network saved in the ONNX format.  For example, a model trained in Pytorch can be exported to ONNX format and imported in Tensorflow and vice versa.&lt;/p&gt;

&lt;p&gt;You don’t need to use Python to read a model saved as ONNX. You can use any programming language of your choice, such as Javascript, C, or C++.&lt;/p&gt;

&lt;p&gt;ONNX makes the model easier to access hardware optimizations. You can apply other optimizations, such as quantization, to your ONNX model.&lt;/p&gt;

&lt;p&gt;Let us see how we can convert our model to ONNX format to use the full benefits of it.&lt;/p&gt;

&lt;p&gt;Let’s see how we can achieve that with the code.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;pathlib&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Path&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;model_repository&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Path&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cwd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parent&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;joinpath&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;models_repository&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;embedding_model_path&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model_repository&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;joinpath&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;retrieval&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;embedding_model&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;1&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;embedding_model_path&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mkdir&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;exist_ok&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parents&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;model_path&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;err&quot;&gt;!&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ls&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model_path&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;__str__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nb&quot;&gt;tuple&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;encoded_input&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;values&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;torch.onnx&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;export&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch_onnx_export&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;torch_onnx_export&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;base_model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;nb&quot;&gt;tuple&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;encoded_input&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;values&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()),&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;embedding_model_path&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;joinpath&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'bio-bert-embedder.onnx'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;input_names&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'input_ids'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'attention_mask'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;dynamic_axes&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'input_ids'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'batch_size'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'sequence'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;
                  &lt;span class=&quot;s&quot;&gt;'attention_mask'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'batch_size'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'sequence'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;
                  &lt;span class=&quot;s&quot;&gt;'last_hidden_state'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'batch_size'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'sequence'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}},&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;do_constant_folding&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;opset_version&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;13&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;base_model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;config&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;save_pretrained&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;embedding_model_path&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;With the above code, we have our model exported into onnx format and ready to be deployed in production.&lt;/p&gt;

&lt;h2 id=&quot;model-deployment-on-docker-with-the-onnx-runtime&quot;&gt;Model deployment on Docker with the ONNX Runtime.&lt;/h2&gt;

&lt;p&gt;In this section, we will learn how  to use the model in a docker container.&lt;/p&gt;

&lt;p&gt;One of the most obvious solutions is to deploy a model and wrap it in with Flask or Fastapi. While this solution can work in practice, it has some latency due to related the fact that the API is written in Python. For this blog I will try a different approach, I will deploy the model using the onnx runtime which is a C++ backend. We will leverage the fact that our model in ONNX format is platform agnostic and we can deploy on any language backend.&lt;/p&gt;

&lt;h3 id=&quot;triton-server&quot;&gt;Triton Server&lt;/h3&gt;

&lt;p&gt;Triton is a software tool for deploying machine learning models for inference. It is designed to produce high-quality inference across different hardware platforms, either GPU or CPU. It also supports inference across cloud, data center, and embedded devices.&lt;/p&gt;

&lt;p&gt;One of the advantages of the triton server is that it supports dynamic batching and concurrent model execution.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Dynamic batching:&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;For models that support batching, which is the case for deep learning models, triton implements scheduling and batching algorithms.  That approach combines individual requests to improve inference throughput.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Concurrency model execution is the capacity to run simultaneously multiple models on the same GPU or various GPUs.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;triton-server-backend&quot;&gt;Triton Server Backend&lt;/h3&gt;

&lt;p&gt;Triton supports different backends to execute the model. A backend is a wrapper around a deep learning framework like Pytorch, TensorFlow, TensorRT, or ONNX Runtime.&lt;/p&gt;

&lt;p&gt;Two backend types interested us for this post: the Python Backend and the ONNX runtime backend.&lt;/p&gt;

&lt;p&gt;The ONNX runtime backend executes ONNX models, and the Python backend allows the writing of the model logic in Python.&lt;/p&gt;

&lt;p&gt;In this post, we will be focused on the ONNX and the Python backend.&lt;/p&gt;

&lt;h3 id=&quot;the-triton-server&quot;&gt;The Triton Server&lt;/h3&gt;

&lt;p&gt;Let us set up the model repository for the triton inference server.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;
&lt;span class=&quot;err&quot;&gt;!&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;touch&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;embedding_model_path&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parent&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;__str__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()}&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;config&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pbtxt&lt;/span&gt;


&lt;span class=&quot;err&quot;&gt;!&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mkdir&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;embedding_model_path&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parent&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;__str__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()}&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ensemble_model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;!&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;touch&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;embedding_model_path&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parent&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;__str__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()}&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ensemble_model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;config&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pbtxt&lt;/span&gt;

&lt;span class=&quot;err&quot;&gt;!&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mkdir&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;embedding_model_path&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parent&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;__str__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()}&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tokenizer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;!&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;touch&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;embedding_model_path&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parent&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parent&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;__str__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()}&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tokenizer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;py&lt;/span&gt;

&lt;span class=&quot;err&quot;&gt;!&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;touch&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;embedding_model_path&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parent&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;__str__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()}&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tokenizer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;config&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pbtxt&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This bash script will create the model repository  for our embedding model. The next section will set up the files in that model repository to run our models.&lt;/p&gt;

&lt;p&gt;The model repository should have three components, the tokenizer, the embedding model, and the ensemble model.
The tokenizer is the configuration of our tokenizer model, it uses the Python backend and handles the tokenization of our text input.
The tokenizer repository should have the files from our tokenizer, the model code, and the model configuration.&lt;/p&gt;

&lt;p&gt;It should have the following layout:&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;└── tokenizer
    ├── 1
    │   ├── __pycache__
    │   ├── config.json
    │   ├── model.py
    │   ├── special_tokens_map.json
    │   ├── tokenizer.json
    │   ├── tokenizer_config.json
    │   └── vocab.txt
    └── config.pbtxt
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;To create the tokenizer file, we will have to save our tokenizer to the tokenizer repository, we will use the following code.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;model_repository&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;

&lt;span class=&quot;n&quot;&gt;tokenizer_path&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model_repository&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;joinpath&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;retrieval&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;tokenizer&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;tokenizer_path&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tokenizer_path&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;joinpath&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;1&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;tokenizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;save_pretrained&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tokenizer_path&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;From that tokenizer we will create the &lt;code class=&quot;language-bash highlighter-rouge&quot;&gt;model.py&lt;/code&gt; file, which will handle the tokeinization part.&lt;/p&gt;

&lt;p&gt;Here is how the model should look like&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;o&quot;&gt;%%&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;writefile&lt;/span&gt;  &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;embedding_model_path&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parent&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parent&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;__str__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()}&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tokenizer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;py&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;os&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;typing&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Dict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;List&lt;/span&gt;

&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;triton_python_backend_utils&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pb_utils&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;transformers&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;AutoTokenizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;PreTrainedTokenizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;TensorType&lt;/span&gt;


&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;TritonPythonModel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;tokenizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;PreTrainedTokenizer&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;initialize&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;args&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Dict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;s&quot;&gt;&quot;&quot;&quot;
        Initialize the tokenization process
        :param args: arguments from Triton config file
        &quot;&quot;&quot;&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# more variables in https://github.com/triton-inference-server/python_backend/blob/main/src/python.cc
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;os&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;join&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;args&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;model_repository&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;args&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;model_version&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tokenizer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;AutoTokenizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;from_pretrained&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;execute&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;requests&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;List[List[pb_utils.Tensor]]&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;s&quot;&gt;&quot;&quot;&quot;
        Parse and tokenize each request
        :param requests: 1 or more requests received by Triton server.
        :return: text as input tensors
        &quot;&quot;&quot;&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;responses&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# for loop for batch requests (disabled in our case)
&lt;/span&gt;        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;request&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;requests&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;c1&quot;&gt;# binary data typed back to string
&lt;/span&gt;            &lt;span class=&quot;n&quot;&gt;query&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;decode&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;UTF-8&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
                &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pb_utils&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get_input_tensor_by_name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;request&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;TEXT&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
                &lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;as_numpy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
                &lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tolist&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
            &lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;tokens&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Dict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ndarray&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tokenizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;text&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;query&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;return_tensors&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;TensorType&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;NUMPY&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;padding&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;truncation&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;
            &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;c1&quot;&gt;# tensorrt uses int32 as input type, ort uses int64
&lt;/span&gt;            &lt;span class=&quot;n&quot;&gt;tokens&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;astype&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;int64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tokens&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;items&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()}&lt;/span&gt;
            &lt;span class=&quot;c1&quot;&gt;# communicate the tokenization results to Triton server
&lt;/span&gt;            &lt;span class=&quot;n&quot;&gt;outputs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;input_name&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tokenizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model_input_names&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;tensor_input&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pb_utils&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Tensor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;input_name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tokens&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;input_name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;outputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tensor_input&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

            &lt;span class=&quot;n&quot;&gt;inference_response&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pb_utils&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;InferenceResponse&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;output_tensors&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;outputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;responses&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;inference_response&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;responses&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The &lt;code class=&quot;language-bash highlighter-rouge&quot;&gt;initialize&lt;/code&gt; method from this class will create our tokenizer from this folder. All our tokenizer files will be initialized from it.&lt;/p&gt;

&lt;p&gt;The &lt;code class=&quot;language-bash highlighter-rouge&quot;&gt;execute&lt;/code&gt; method is the one that handles the request. It can take multiple requests and parse them. Finally,   create the  query from the text, and return the tokenized text.&lt;/p&gt;

&lt;p&gt;With our tokenizer setup, let us configure the Python server to use it.&lt;/p&gt;

&lt;p&gt;The content of the &lt;code class=&quot;language-bash highlighter-rouge&quot;&gt;tokenizer/config.pbxt&lt;/code&gt; should look like this.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;o&quot;&gt;%%&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;writefile&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;embedding_model_path&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parent&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parent&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;__str__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()}&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tokenizer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;config&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pbtxt&lt;/span&gt;


&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;tokenizer&quot;&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;max_batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;backend&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;python&quot;&lt;/span&gt;

&lt;span class=&quot;nb&quot;&gt;input&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;TEXT&quot;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;data_type&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;TYPE_STRING&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;dims&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;output&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;input_ids&quot;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;data_type&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;TYPE_INT64&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;dims&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;attention_mask&quot;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;data_type&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;TYPE_INT64&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;dims&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;instance_group&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;kind&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;KIND_CPU&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;In this file, we specify that our backend is a Python backend.  It will take an input named text, with dimension -1. The dimension -1 which means dynamic or it can be of any size. It returns the inputs_ids, and the attention_mask and will run on a CPU.&lt;/p&gt;

&lt;p&gt;The second component of our model is the embedding model itself, it has the following layout:&lt;/p&gt;
&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;├── embedding_model
│   ├── 1
│   │   ├── bio-bert-embedder.onnx
│   │   └── config.json
│   └── config.pbtxt

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Let look at the &lt;code class=&quot;language-bash highlighter-rouge&quot;&gt;config.pbtxt&lt;/code&gt; for the embedding model&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;embedding_model_path&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;o&quot;&gt;%%&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;writefile&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;embedding_model_path&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parent&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;__str__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()}&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;config&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pbtxt&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;embedding_model&quot;&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;platform&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;onnxruntime_onnx&quot;&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;backend&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;onnxruntime&quot;&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;default_model_filename&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;bio-bert-embedder.onnx&quot;&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;max_batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;input&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;input_ids&quot;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;data_type&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;TYPE_INT64&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;dims&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;attention_mask&quot;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;data_type&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;TYPE_INT64&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;dims&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;output&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;3391&quot;&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# not sure why this is name 3391, need to double check
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;data_type&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;TYPE_FP32&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;dims&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1024&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;instance_group&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;kind&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;KIND_CPU&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;It is the configuration file for our embedding model, we can see that it takes the output from our tokenizer model and produces the embedding vector of shape, -1, 1024. With -1 meaning the dynamic shape, and 1024 is our embedding size.&lt;/p&gt;

&lt;p&gt;Note: for some reason, the model output is named &lt;code class=&quot;language-bash highlighter-rouge&quot;&gt;3391&lt;/code&gt; I  don’t know why it is named like that.&lt;/p&gt;

&lt;p&gt;We can connect our embedding model and the tokenizer’s input and output with the ensemble model. It should have the following layout:&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;├── ensemble_model
│   ├── 1
│   └── config.pbtxt
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;And the content of the &lt;code class=&quot;language-bash highlighter-rouge&quot;&gt;config.pbtxt&lt;/code&gt; file in the ensemble model should be like this:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;o&quot;&gt;%%&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;writefile&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;embedding_model_path&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parent&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parent&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;__str__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()}&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ensemble_model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;config&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pbtxt&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;ensemble_model&quot;&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# maximum batch size 
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;max_batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt; 
&lt;span class=&quot;n&quot;&gt;platform&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;ensemble&quot;&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;#input to the model 
&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;input&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;TEXT&quot;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;data_type&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;TYPE_STRING&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;dims&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; 
    &lt;span class=&quot;c1&quot;&gt;# -1 means dynamic axis, aka this dimension may change 
&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;#output of the model 
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;output&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;3391&quot;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;data_type&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;TYPE_FP32&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;dims&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1024&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; 
    &lt;span class=&quot;c1&quot;&gt;# two dimensional tensor, where 1st dimension: batch-size, 2nd dimension: #classes, not sure why name is 3391.
&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;#Type of scheduler to be used
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ensemble_scheduling&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;step&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;model_name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;tokenizer&quot;&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;model_version&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;input_map&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;key&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;TEXT&quot;&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;TEXT&quot;&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;output_map&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;key&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;input_ids&quot;&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;input_ids&quot;&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;key&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;attention_mask&quot;&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;attention_mask&quot;&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;model_name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;embedding_model&quot;&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;model_version&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;input_map&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;
            &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;key&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;input_ids&quot;&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;input_ids&quot;&lt;/span&gt;
            &lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;
            &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;key&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;attention_mask&quot;&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;attention_mask&quot;&lt;/span&gt;
            &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;output_map&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;key&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;3391&quot;&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;3391&quot;&lt;/span&gt;
            &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;In a nutshell, this config connects our tokenizer and the embedding model. The output of the tokenizer model is passed to the embedding model to produce the embedding vector.&lt;/p&gt;

&lt;p&gt;If the three components were configured correctly we should have the following layout:&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;
models_repository/retrieval
├── embedding_model
│   ├── 1
│   │   ├── bio-bert-embedder.onnx
│   │   └── config.json
│   └── config.pbtxt
├── ensemble_model
│   ├── 1
│   └── config.pbtxt
└── tokenizer
    ├── 1
    │   ├── __pycache__
    │   ├── config.json
    │   ├── model.py
    │   ├── special_tokens_map.json
    │   ├── tokenizer.json
    │   ├── tokenizer_config.json
    │   └── vocab.txt
    └── config.pbtxt

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;If you have all the following components we can go to the next stage.&lt;/p&gt;

&lt;h3 id=&quot;building-the-triton-inference-server-image&quot;&gt;Building the triton Inference server image.&lt;/h3&gt;

&lt;p&gt;In this section, we will see how to build the triton inference server image. The base triton inference server docker image is huge and can weigh up to 10 GB. In the triton inference server there is a way to build a Cpu only image for triton.  I wasn’t able to build it from my Macbook.&lt;/p&gt;

&lt;p&gt;We will be using the image &lt;a href=&quot;https://github.com/Jackiexiao&quot;&gt;Jackie Xiao&lt;/a&gt; built for that purpose.&lt;/p&gt;

&lt;p&gt;It is a CPU-only image, hence the small size of 500Mb. If you are deploying the model in an infrastructure with a GPU, you will need to use the full Triton Image which is huge.&lt;/p&gt;

&lt;p&gt;Here is the docker file used to build this image.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;o&quot;&gt;%%&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;writefile&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Path&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cwd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parent&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;__str__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()}&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Dockerfile&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Use the base image
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;jackiexiao&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tritonserver&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;23.12&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;onnx&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;py&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cpu&lt;/span&gt;



&lt;span class=&quot;c1&quot;&gt;# Install the required Python packages
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;RUN&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pip&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;install&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;transformers&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;==&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;4.27&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sacremoses&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;==&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;


&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;You can see that we are pulling the base image and install in it the transformer and the Moses tokenizer.&lt;/p&gt;

&lt;p&gt;With that docker image, we can build the docker image.&lt;/p&gt;

&lt;p&gt;` docker build -t espymur/triton-onnx-cpu:dev  -f Dockerfile .`&lt;/p&gt;

&lt;p&gt;If the image was successfully built we push it to the docker image repository:&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;language-bash highlighter-rouge&quot;&gt;docker push espymur/triton-onnx-cpu:dev&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;After pushing the image to the repository, you can start your docker container with the triton server in it.&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;
 docker run &lt;span class=&quot;nt&quot;&gt;--rm&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-p&lt;/span&gt; 8000:8000 &lt;span class=&quot;nt&quot;&gt;-p&lt;/span&gt; 8001:8001 &lt;span class=&quot;nt&quot;&gt;-p&lt;/span&gt; 8002:8002  &lt;span class=&quot;nt&quot;&gt;-v&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;PWD&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;/models_repository/retrieval:/models  espymur/triton-onnx-cpu:dev tritonserver &lt;span class=&quot;nt&quot;&gt;--model-repository&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;/models

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This command does the following:&lt;/p&gt;

&lt;p&gt;It starts the docker container with the triton-onnx-cpu:dev image.&lt;/p&gt;

&lt;p&gt;It exposes the different ports from the container to the external environment:&lt;/p&gt;

&lt;p&gt;For HTTP connection,  it maps the port 8000 from the container to the port 8000 of the external environment.&lt;/p&gt;

&lt;p&gt;For GRPC, it maps the port 8001 to the port 8001.&lt;/p&gt;

&lt;p&gt;For the metric server, it maps the port 8002 to the port 8002&lt;/p&gt;

&lt;p&gt;It maps the local directory, named &lt;code class=&quot;language-bash highlighter-rouge&quot;&gt;model_repository&lt;/code&gt; to the folder named &lt;code class=&quot;language-bash highlighter-rouge&quot;&gt;/models&lt;/code&gt; in the docker container by using volumes.&lt;/p&gt;

&lt;p&gt;We specify that the triton server should use the model folder as the model repository.&lt;/p&gt;

&lt;p&gt;If everything goes well with that command you should be able to see the following output which tells us which port is used by the model.&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;
I0329 18:42:18.452806 1 grpc_server.cc:2495] Started GRPCInferenceService at 0.0.0.0:8001

I0329 18:42:18.460674 1 http_server.cc:4619] Started HTTPService at 0.0.0.0:8000

I0329 18:42:18.520315 1 http_server.cc:282] Started Metrics Service at 0.0.0.0:8002

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;With that code, we have our embedding API running and we can now send requests to it.&lt;/p&gt;

&lt;h3 id=&quot;making-request-to-the-inference-server&quot;&gt;Making Request to the inference Server.&lt;/h3&gt;

&lt;p&gt;We have now built our model, the next step is to make an inference request to it and analyze the response.&lt;/p&gt;

&lt;p&gt;Since the model is deployed as a REST API you can make inference requests to it using any client of your choice in any language&lt;/p&gt;

&lt;p&gt;.  The inference server is very strict in terms of what it expects as input, and how to interact with it. Fortunately, they have described different clients to use to build the inputs.&lt;/p&gt;

&lt;p&gt;For demonstration purposes, I will be using the Python HTTP client to make the inference requests.&lt;/p&gt;

&lt;p&gt;But nothing restricted you from using your language of choice to make HTTP requests to the API.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;tritonclient.http&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;httpclient&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;url&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;localhost:8000&quot;&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;http_client&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;httpclient&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;InferenceServerClient&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;url&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;url&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;verbose&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
                  
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The above code creates the http client, with our server url, let us define the input and output of it.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;text_input&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;httpclient&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;InferInput&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'TEXT'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;datatype&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'BYTES'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;embedding_output&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;httpclient&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;InferRequestedOutput&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;3391&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;binary_data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Those are the placeholder for our inputs and output, let us fill them now:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;sentences&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;what cause covid&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;np_input_data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;asarray&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sentences&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dtype&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;object&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;np_input_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reshape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;text_input&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;set_data_from_numpy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np_input_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reshape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;results&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;http_client&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;infer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model_name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;ensemble_model&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;inputs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;text_input&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;outputs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;embedding_output&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;results&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;We can now convert back the output to numpy using&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;inference_output&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;results&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;as_numpy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'3391'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;inference_output&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;That is all we have our embedding API, which takes the text and produces the embedding vector.&lt;/p&gt;

&lt;h3 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h3&gt;

&lt;p&gt;In this post, we have learned how to deploy an embedding model as an API using the triton inference server. The knowledge learned in this post can be used to deploy any transformer model  with an encoder or decoder using the triton inference server. Any model from the BERT, or GPT family.  It can slightly  be adapted to use with encoder-decoder models such as T5 or M2M.&lt;/p&gt;

&lt;p&gt;Once we deploy the model to the production server it will grow with users and need to scale. In the second part of this series, we will learn how to scale the model using Kubernetes.&lt;/p&gt;

</description>
        <pubDate>Sun, 07 Apr 2024 23:12:57 +0100</pubDate>
        <link>http://localhost:4000/deploying-language-model-with-onnx-runtime-on-triton-inference-server</link>
        <guid isPermaLink="true">http://localhost:4000/deploying-language-model-with-onnx-runtime-on-triton-inference-server</guid>
        
        
      </item>
    
      <item>
        <title>Getting Started with Seldon-core and Kubernetes, Part 1: My Struggles with Kubernetes</title>
        <description>
&lt;figure&gt;
  &lt;p&gt;&lt;img src=&quot;/assets/posts/2023-03-07-struggles-with-docker/container-repair.png&quot; /&gt;&lt;/p&gt;
  &lt;figcaption&gt; Mechanic fixing container image by : &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;Learning Kubernetes has been on my bucket list for years. I always said that when I had the time, I would learn it because it is one of those tools missing from my developer toolbox.&lt;/p&gt;

&lt;p&gt;In January, I decided to start my learning journey. I watched this amazing video, which gave me a basic overview of Kubernetes components, and I managed to install it on my local laptop.&lt;/p&gt;

&lt;p&gt;To practice, I used Kubernetes to deploy a machine learning model. After researching, I found out that there are currently two tools used to deploy machine learning models using Kubernetes: Kserve and Seldon-core. After struggling to run Kserve on my machine, I decided to go with Seldon-core because it was well-documented and seemed more mature compared to Kserve. While following the getting started tutorial on Seldon-core, I encountered some bugs that tested my knowledge of Kubernetes. In this post, I will write about some of them, how I encountered them, and the lessons I learned from them.&lt;/p&gt;

&lt;p&gt;The tutorial describes how to create a machine learning service on top of Kubernetes that will be used to make predictions.&lt;/p&gt;

&lt;p&gt;My troubles and bugs started when I ran the following command to create the Seldon deployment:&lt;/p&gt;

&lt;figure&gt;
  &lt;p&gt;&lt;img src=&quot;/assets/posts/2023-03-07-struggles-with-docker/seldon-core.png&quot; /&gt;&lt;/p&gt;
  &lt;figcaption&gt;Overview of Seldon Core Components&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;yaml
&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;kubectl apply &lt;span class=&quot;nt&quot;&gt;-f&lt;/span&gt; - &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;END&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;
apiVersion: machinelearning.seldon.io/v1
kind: SeldonDeployment
metadata:
  name: iris-model
  namespace: seldon
spec:
  name: iris
  predictors:
  - graph:
      implementation: SKLEARN_SERVER
      modelUri: gs://seldon-models/v1.16.0-dev/sklearn/iris
      name: classifier
    name: default
    replicas: 1
&lt;/span&gt;&lt;span class=&quot;no&quot;&gt;END
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This command was supposed to start a SeldonDeployment, which consists of a deployment, a service, and a pod running the model. I hoped that the command would run successfully, but it didn’t. Over the past three days, I faced different errors that made me learn more about Kubernetes. Let me talk about the first one.&lt;/p&gt;

&lt;h2 id=&quot;downgrading-kubernetes-version-with-docker-desktop&quot;&gt;Downgrading Kubernetes version with Docker Desktop.&lt;/h2&gt;
&lt;p&gt;I don’t remember many details about the first bug I faced because I didn’t document it much. I remember using Docker Desktop as a backend for Kubernetes, and it was using Kubernetes 1.26. The fix for the issue was to use a lower version of Kubernetes, such as 1.24, but with Docker Desktop, there is no way to downgrade the version of Kubernetes. I had to switch to using Minikube; with it, I could specify the version of Kubernetes to use. Here is the command I used to downgrade it:&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;language-bash highlighter-rouge&quot;&gt;minikube start &lt;span class=&quot;nt&quot;&gt;--kubernetes-version&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;v1.24.1&lt;/code&gt;&lt;/p&gt;

&lt;h2 id=&quot;unable-to-pull-the-large-images-in-the-pod&quot;&gt;Unable to pull the large images in the pod.&lt;/h2&gt;

&lt;p&gt;After solving the first issue, I faced another one. I noticed my pod was not starting, so I decided to debug the pod to find out what was going wrong. When I checked the pod’s status, I found that it was stuck with this message: Error: ImagePullBackOff. I ran the following command:&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;language-bash highlighter-rouge&quot;&gt;kubectl describe pod PodName &lt;span class=&quot;nt&quot;&gt;-n&lt;/span&gt; podNamespace.&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;And I ended up with the following error message:&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;
  Normal   Scheduled  13m   default-scheduler  Successfully assigned seldon/xgboost-default-0-classifier-786f456bd4-jxjm6 to minikube
  Normal   Pulled     13m   kubelet   Container image &lt;span class=&quot;s2&quot;&gt;&quot;seldonio/rclone-storage-initializer:1.15.0&quot;&lt;/span&gt; already present on machine
  Normal   Created    13m   kubelet   Created container classifier-model-initializer
  Normal   Started    13m   kubelet   Started container classifier-model-initializer
  Warning  Failed     10m   kubelet   Error: ErrImagePull
  Warning  Failed     10m   kubelet   Failed to pull image &lt;span class=&quot;s2&quot;&gt;&quot;seldonio/xgboostserver:1.15.0&quot;&lt;/span&gt;: rpc error: code &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; Unknown desc &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; context deadline exceeded
  Normal   Pulled     10m   kubelet   Container image &lt;span class=&quot;s2&quot;&gt;&quot;docker.io/seldonio/seldon-core-executor:1.15.0&quot;&lt;/span&gt; already present on machine
  Normal   Created    10m   kubelet   Created container seldon-container-engine
  Normal   Started    10m   kubelet   Started container seldon-container-engine
  Normal   BackOff    9m58s &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;x2 over 9m59s&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;   kubelet   Back-off pulling image &lt;span class=&quot;s2&quot;&gt;&quot;seldonio/xgboostserver:1.15.0&quot;&lt;/span&gt;
  Warning  Failed     9m58s &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;x2 over 9m59s&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;   kubelet   Error: ImagePullBackOff
  Normal   Pulling    9m45s &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;x2 over 13m&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;     kubelet   Pulling image &lt;span class=&quot;s2&quot;&gt;&quot;seldonio/xgboostserver:1.15.0&quot;&lt;/span&gt;
  Warning  Unhealthy  3m14s &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;x84 over 9m39s&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;  kubelet   Readiness probe failed: HTTP probe failed with statuscode: 503
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The first lines of the logs show that Kubernetes could not pull the image for my container:&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;language-bash highlighter-rouge&quot;&gt;kubelet Failed to pull image &lt;span class=&quot;s2&quot;&gt;&quot;seldonio/xgboostserver:1.15.0&quot;&lt;/span&gt;: rpc error: code &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; Unknown desc &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; context deadline exceeded&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;Initially, I thought that my pod was not connected to the internet because it could not pull the container image, but that was not the case. On closer inspection, I found that the pod could pull the &lt;code class=&quot;language-bash highlighter-rouge&quot;&gt;docker.io/seldonio/seldon-core-executor:1.15.0&lt;/code&gt; container image and was starting the executor container but not the MLServer image.&lt;/p&gt;

&lt;p&gt;After several hours of debugging, I discovered that the error was due to the size of my image and the timeout while pulling the image for the first time. The container was trying to pull the images, but it took a long time to pull, and the container timed out. After Googling, two possible workarounds were suggested:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Increase the size of the runtime timeout to a larger time and hope it will work.&lt;/li&gt;
  &lt;li&gt;Download the images with a separate command and run the container once the image is downloaded in the machine.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;To apply the first workaround, I had to run the following command:&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;language-bash highlighter-rouge&quot;&gt;minikube ssh &lt;span class=&quot;s2&quot;&gt;&quot;sudo sed -i 's/KUBELET_ARGS=/KUBELET_ARGS=--runtime-request-timeout=TIME /g' /etc/systemd/system/kubelet.service.d/10-kubeadm.conf &amp;amp;&amp;amp; sudo systemctl daemon-reload &amp;amp;&amp;amp; sudo systemctl restart kubelet&quot;&lt;/span&gt;&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;I tried it, but it didn’t work in my case, so I had to use the second method, which consists of downloading the image separately inside Minikube. I used the following command:&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;language-bash highlighter-rouge&quot;&gt;minikube image load seldonio/sklearnserver:1.15.0&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;The image was large and took approximately 10 minutes to download, maybe because my internet connection this weekend was not at its best. But after that, I passed that issue, but that was not all. There was another bug waiting for me:&lt;/p&gt;

&lt;figure&gt;
  &lt;p&gt;&lt;img src=&quot;/assets/posts/2023-03-07-struggles-with-docker/car-fails-to-start.jpeg&quot; /&gt;&lt;/p&gt;
  &lt;figcaption&gt;Car failing to start&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;h2 id=&quot;readiness-probe-failed&quot;&gt;Readiness probe failed&lt;/h2&gt;

&lt;p&gt;When I described my pod, I found that the image was pulled and the container was running for a few seconds, and then it stopped with this message:&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;language-bash highlighter-rouge&quot;&gt;kubelet Readiness probe failed: HTTP probe failed with statuscode: 503&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;When I read about the error message, I found that Kubernetes uses readiness probes to know if a container is ready to accept traffic. The service keeps sending the request to the pod until the pod is ready to accept the traffic. So it was not passing that status. It is an error on the container side. But the container was stopped; how could I log in to a stopped container? I found this command:&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;language-bash highlighter-rouge&quot;&gt;kubectl logs podName &lt;span class=&quot;nt&quot;&gt;-c&lt;/span&gt; ContainerName &lt;span class=&quot;nt&quot;&gt;-n&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;seldon&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;By checking the log of the container to my satisfaction, I found that the container was failing because of an error with the Python image. I fixed it by changing the container image I used in my deployment. Then I had everything running.&lt;/p&gt;

&lt;p&gt;With the pod running and the service working, how could I connect to the container inside a cluster? I had to create an ingress component connecting to the external service serving my pod on port 9000, where the model was running. I did everything to set up the ingress, but I could not connect to the internal service on my Mac.&lt;/p&gt;

&lt;p&gt;I spent quite some time learning about Kubernetes networking and how services work, but networking is out of the scope of this tutorial. In the short term, I had to use tunneling to access my ingress from outside the container.&lt;/p&gt;

&lt;p&gt;Thanks to this &lt;a href=&quot;https://stackoverflow.com/a/73735009/4683950&quot;&gt;stackoverflow question&lt;/a&gt;, which provided the steps to solve the issue, I finally managed to access the deployment. However, when I attempted to access the URL, I discovered that it was not working and all of the endpoints on the server were returning a 404 error. Although I have not yet solved the issue, I plan to do so soon.&lt;/p&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;Yes, I did struggles a lot, but this was a good learning lesson for me.  I learned how to debug containers on kubernetes and how minikube works with kuberenetes. I also learn some bit of kubernetes networking. I hope this post will serve my future self if I am facing the same issue as well as anyone else who is struggling with those bugs. My journey is not completed yet, I haven’t managed to deploy a large language model on Kubernetes, I am still struggling with that. In part two of this post I will talk about how I managed to deploy a transformer model with kubernetes.&lt;/p&gt;
</description>
        <pubDate>Tue, 07 Mar 2023 10:03:59 +0000</pubDate>
        <link>http://localhost:4000/struggles-with-docker</link>
        <guid isPermaLink="true">http://localhost:4000/struggles-with-docker</guid>
        
        <category>docker,</category>
        
        <category>kubernetes,</category>
        
        <category>devops</category>
        
        
      </item>
    
      <item>
        <title>Information Retrieval on the COVID-19 Open Research Dataset (CORD-19) Part one: TF-IDF and Cosine Similarity</title>
        <description>&lt;h2 id=&quot;scenario&quot;&gt;Scenario&lt;/h2&gt;

&lt;p&gt;In response to the COVID-19 pandemic, the White House and a coalition of leading research groups have prepared the &lt;a href=&quot;https://www.kaggle.com/allen-institute-for-ai/CORD-19-research-challenge&quot;&gt;COVID-19&lt;/a&gt; Open Research Dataset (CORD-19). CORD-19 is a resource of over 181,000 scholarly articles, including over 80,000 with full text, about COVID-19, SARS-CoV-2, and related coronaviruses. This freely available dataset is provided to the global research community to apply recent advances in Information Retrieval and other AI techniques to generate new insights in support of the ongoing fight against this infectious disease. There is a growing urgency for these approaches because of the rapid acceleration in new coronavirus literature, making it difficult for the medical research community to keep up.&lt;/p&gt;

&lt;h2 id=&quot;the-task&quot;&gt;The task&lt;/h2&gt;
&lt;p&gt;For this tutorial, we will write an Information Retrieval pipeline that helps anyone to query the cord-19 dataset and find relevant articles for their queries.&lt;/p&gt;

&lt;p&gt;We will show two different approaches to building that pipeline. The first approach uses the TF-IDF and cosine similarity between the query and the articles. We will use Elasticsearch with the python API to search our articles for the second one.&lt;/p&gt;

&lt;p&gt;For the first step, we will leverage the TF-IDF vectorizer from Sklearn. In contrast, for the second one, we will leverage the python &lt;a href=&quot;https://github.com/elastic/elasticsearch-dsl-py&quot;&gt;elastic search dsl&lt;/a&gt;.  If you are  familiar with ORMs, this library is like an object-relational framework to interact with the elastic search database. If you have a background in python and some NLP experience, this is a fantastic tool for a smooth interaction with elastic search.&lt;/p&gt;

&lt;p&gt;This series is a part of an assignment I did for my Information Retrieval course. I decided to publish it online because of the lack of relevant tutorials on this topic.&lt;/p&gt;

&lt;p&gt;This will be a two parts tutorial.&lt;/p&gt;

&lt;p&gt;For the first part:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Data Collection:&lt;/strong&gt; In this section, we will go through downloading the dataset from Kaggle and saving it as a csv file.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Data Cleaning:&lt;/strong&gt; We will pre-process and clean the text.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Keyword selection:&lt;/strong&gt; We will use TF-IDF to find the appropriate keywords for each document.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Querying&lt;/strong&gt; : In this section we will query the article using TF-IDF.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;For the second part:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Model Creation and Indexing: We will build our elastic search model and create our index in the database.&lt;/li&gt;
  &lt;li&gt;Querying: We will show to perform some simple queries on our database and preprocess the results.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;For this series, I am assuming the following:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;You have elastic-search installed and running on your computer.&lt;/li&gt;
  &lt;li&gt;You have Python 3.7 installed.&lt;/li&gt;
  &lt;li&gt;You are familiar with the basics of text processing in Python and Object-Relational Mapping(ORM).&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;If that is the case for you, let’s get started.&lt;/p&gt;

&lt;figure&gt;
  &lt;p&gt;&lt;img src=&quot;/assets/posts/2022-04-07-information-retrieval-on-medical-research-papers-about-covid19/information-retrieval-system.png&quot; /&gt;&lt;/p&gt;
  &lt;figcaption&gt;Our Information Retrieval pipeline&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;h2 id=&quot;data-collection&quot;&gt;Data Collection&lt;/h2&gt;

&lt;p&gt;In this section, we will go through downloading the dataset from Kaggle and how to process it in chunks.&lt;/p&gt;

&lt;p&gt;The dataset is huge, and for this tutorial, we will use only the metadata release alongside the dataset.&lt;/p&gt;

&lt;h3 id=&quot;downloading-the-metadata-file&quot;&gt;Downloading the metadata file&lt;/h3&gt;

&lt;p&gt;The simplest way to download the data is to head to the &lt;a href=&quot;https://www.kaggle.com/allen-institute-for-ai/CORD-19-research-challenge?select=metadata.csv&quot;&gt;competition link&lt;/a&gt; then select the metadata.csv file, and finally, click on the download button to download it and save it in a place in your local machine.&lt;/p&gt;

&lt;p&gt;The data comes as a zip file; you will have to unzip it to start using it.&lt;/p&gt;

&lt;h3 id=&quot;reading-the-dataset-with-dask&quot;&gt;Reading the dataset with Dask.&lt;/h3&gt;

&lt;p&gt;The dataset is huge. It has more than 1.5Gb. We will use dask and pandas to read the file to make our life easier.&lt;/p&gt;

&lt;p&gt;Make sure to have &lt;a href=&quot;https://docs.dask.org/en/stable/&quot;&gt;dask&lt;/a&gt; and &lt;a href=&quot;https://pandas.pydata.org/&quot;&gt;pandas&lt;/a&gt; installed in your environment for this project.&lt;/p&gt;

&lt;p&gt;With the file downloaded in your local machine, dask and pandas installed, let us write the first code to read the dataset.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt;  &lt;span class=&quot;nn&quot;&gt;pandas&lt;/span&gt;  &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt;  &lt;span class=&quot;nn&quot;&gt;pathlib&lt;/span&gt;  &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;Path&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt;  &lt;span class=&quot;nn&quot;&gt;dask.dataframe&lt;/span&gt;  &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;dd&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt;  &lt;span class=&quot;nn&quot;&gt;numpy&lt;/span&gt;  &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;If the libraries are well imported, let us read the file.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;DATA_PATH&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Path&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cwd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;joinpath&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;data&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;metadata_path&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;DATA_PATH&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;joinpath&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;metadata.csv&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;read_csv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;metadata_path&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;dtype&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;pubmed_id&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;object0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;  &lt;span class=&quot;s&quot;&gt;'arxiv_id'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;  &lt;span class=&quot;s&quot;&gt;'object'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;  &lt;span class=&quot;s&quot;&gt;'who_covidence_id'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;  &lt;span class=&quot;s&quot;&gt;'object'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;})&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Those lines, call the read_csv from function from dask to read the file and specify some columns data mapping.
Under the assumption that you have a data folder on the same level as this jupyter notebook and it is named &lt;code class=&quot;language-bash highlighter-rouge&quot;&gt;metadata.csv&lt;/code&gt;. If that is not the case , you can pass the exact path of your csv file to the &lt;code class=&quot;language-bash highlighter-rouge&quot;&gt;read_csv&lt;/code&gt; function.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Why is Dask faster than Pandas?&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Remember, we are dealing with a large dataset. Pandas would like to load the whole data in memory. But for a small computer, 1.7 Gb is a lot of data to fit in memory, which would take us a lot of time.&lt;/p&gt;

&lt;p&gt;A workaround for this problem would be to read our dataset in different chunks with pandas. Dask is doing almost the same, it read the dataset in parallel using chunk but transparently for the end users.&lt;/p&gt;

&lt;p&gt;It avoids us writing a lot of code that will read the data in chunks, process each chunk in parallel, and combine the whole data in one dataset. Check this tutorial &lt;a href=&quot;https://pythonspeed.com/articles/faster-pandas-dask/&quot;&gt;here&lt;/a&gt; for more details about how dask is faster than pandas.&lt;/p&gt;

&lt;p&gt;Once our data is read, let us select a subset for our tutorial.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;important_columns&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;pubmed_id&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;  &lt;span class=&quot;s&quot;&gt;&quot;title&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;  &lt;span class=&quot;s&quot;&gt;&quot;abstract&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;  &lt;span class=&quot;s&quot;&gt;&quot;journal&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;  &lt;span class=&quot;s&quot;&gt;&quot;authors&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;  &lt;span class=&quot;s&quot;&gt;&quot;publish_time&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The dataset has 59k rows but for this exercice will will only work this the a sample of 1000 rows which is roughly the 1/60 of the whole dataframe&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;sample_df&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sample&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;frac&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;float&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;300&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;sample_df&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sample_df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dropna&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;subset&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;important_columns&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;sample_df&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sample_df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;important_columns&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;We are still using a dask dataframe; let us convert it to a pandas dataframe.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;data_df&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sample_df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;compute&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This line creates the pandas dataframe we will be working with for the rest of the tutorial.
The bellow lines will drop null values in the abstract of the dataset and&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;data_df&lt;/span&gt;  &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;data_df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dropna&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;subset&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'abstract'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;rows&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;data_df&lt;/span&gt;  &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;data_df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;set_index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;pubmed_id&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;data_df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;head&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;pubmed_id&lt;/th&gt;
      &lt;th&gt;title&lt;/th&gt;
      &lt;th&gt;abstract&lt;/th&gt;
      &lt;th&gt;journal&lt;/th&gt;
      &lt;th&gt;authors&lt;/th&gt;
      &lt;th&gt;publish_time&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;32165633&lt;/td&gt;
      &lt;td&gt;Acid ceramidase of macrophages traps herpes si…&lt;/td&gt;
      &lt;td&gt;Macrophages have important protective function…&lt;/td&gt;
      &lt;td&gt;Nat Commun&lt;/td&gt;
      &lt;td&gt;Lang, Judith; Bohn, Patrick; Bhat, Hilal; Jast…&lt;/td&gt;
      &lt;td&gt;2020-03-12&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;18325284&lt;/td&gt;
      &lt;td&gt;Resource Allocation during an Influenza Pandemic&lt;/td&gt;
      &lt;td&gt;Resource Allocation during an Influenza Pandemic&lt;/td&gt;
      &lt;td&gt;Emerg Infect Dis&lt;/td&gt;
      &lt;td&gt;Paranthaman, Karthikeyan; Conlon, Christopher …&lt;/td&gt;
      &lt;td&gt;2008-03-01&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;30073452&lt;/td&gt;
      &lt;td&gt;Analysis of pig trading networks and practices…&lt;/td&gt;
      &lt;td&gt;East Africa is undergoing rapid expansion of p…&lt;/td&gt;
      &lt;td&gt;Trop Anim Health Prod&lt;/td&gt;
      &lt;td&gt;Atherstone, C.; Galiwango, R. G.; Grace, D.; A…&lt;/td&gt;
      &lt;td&gt;2018-08-02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;35017151&lt;/td&gt;
      &lt;td&gt;Pembrolizumab and decitabine for refractory or…&lt;/td&gt;
      &lt;td&gt;BACKGROUND: The powerful ‘graft versus leukemi…&lt;/td&gt;
      &lt;td&gt;J Immunother Cancer&lt;/td&gt;
      &lt;td&gt;Goswami, Meghali; Gui, Gege; Dillon, Laura W; …&lt;/td&gt;
      &lt;td&gt;2022-01-11&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;34504521&lt;/td&gt;
      &lt;td&gt;Performance Evaluation of Enterprise Supply Ch…&lt;/td&gt;
      &lt;td&gt;In order to make up for the shortcomings of cu…&lt;/td&gt;
      &lt;td&gt;Comput Intell Neurosci&lt;/td&gt;
      &lt;td&gt;Bu, Miaoling&lt;/td&gt;
      &lt;td&gt;2021-08-30&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;The dataframe contains the following columns :&lt;/p&gt;

&lt;p&gt;The pub med id is a unique id to identify the article.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Title: the title of the research paper&lt;/li&gt;
  &lt;li&gt;authors: the author of the paper&lt;/li&gt;
  &lt;li&gt;publish time: the date the paper was published 
The abstract is the abstract of the paper, which is the text we will use for indexing purposes for this work.
With our pandas dataset in place, let us move to the next part: text processing.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;text-processing&quot;&gt;Text Processing&lt;/h2&gt;

&lt;figure&gt;
  &lt;p&gt;&lt;img src=&quot;/assets/posts/2022-04-07-information-retrieval-on-medical-research-papers-about-covid19/text-processing-part.png&quot; /&gt;&lt;/p&gt;
  &lt;figcaption&gt;The text Processing Part&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;In this part, we will perform text processing. Our input is the raw text for the paper abstract for this section. Our output is the cleaned version of the input text.
Our preprocessing consists of the following steps: tokenization, lemmatization, stop word removal, lowercasing, special characters, and number removal.&lt;/p&gt;

&lt;p&gt;For this step, we will be using &lt;a href=&quot;https://spacy.io/usage&quot;&gt;Spacy&lt;/a&gt;,&lt;a href=&quot;https://www.nltk.org/install.html&quot;&gt;NLTK&lt;/a&gt;, and regular expressions to perform our preprocessing. Ensure you have spacy and NLTK installed before running the code in this section. Check also if you have installed the &lt;code class=&quot;language-bash highlighter-rouge&quot;&gt;en_core_web_sm&lt;/code&gt; package. If not install it from this &lt;a href=&quot;https://spacy.io/models/en#en_core_web_sm&quot;&gt;link&lt;/a&gt;&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt;  &lt;span class=&quot;nn&quot;&gt;spacy&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt;  &lt;span class=&quot;nn&quot;&gt;nltk&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt;  &lt;span class=&quot;nn&quot;&gt;re&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;nlp&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;spacy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;load&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'en_core_web_sm'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;stopwords_list&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nltk&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;corpus&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;stopwords&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;words&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'english'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;tokenization&quot;&gt;Tokenization&lt;/h3&gt;

&lt;p&gt;Tokenization is the process of splitting a document into tokens, basically splitting a bunch of text into words. Spacy has a built-in tokenizer that helps us with this.&lt;/p&gt;

&lt;h3 id=&quot;stopwords-removal&quot;&gt;Stopwords removal.&lt;/h3&gt;

&lt;p&gt;Stop words are words that have no special significance when analyzing the text. Those words are frequent in the corpus but are useless for our analysis and example of them are &lt;strong&gt;&lt;em&gt;a&lt;/em&gt;&lt;/strong&gt;, &lt;strong&gt;&lt;em&gt;an&lt;/em&gt;&lt;/strong&gt;, &lt;strong&gt;&lt;em&gt;the&lt;/em&gt;&lt;/strong&gt;, &lt;strong&gt;&lt;em&gt;and&lt;/em&gt;&lt;/strong&gt; the like.&lt;/p&gt;

&lt;p&gt;The following function will perform stop word removal for us :&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt;  &lt;span class=&quot;nf&quot;&gt;remove_stopwords&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;is_lower_case&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;tokens&lt;/span&gt;  &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;nltk&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;word_tokenize&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;tokens&lt;/span&gt;  &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;  &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;token&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;strip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;token&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tokens&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;is_lower_case&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;filtered_tokens&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;token&lt;/span&gt;  &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;token&lt;/span&gt;  &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;tokens&lt;/span&gt;  &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;token&lt;/span&gt;  &lt;span class=&quot;ow&quot;&gt;not&lt;/span&gt;  &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;stopwords_list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;filtered_tokens&lt;/span&gt;  &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;  &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;token&lt;/span&gt;  &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;token&lt;/span&gt;  &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;tokens&lt;/span&gt;  &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;token&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lower&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;  &lt;span class=&quot;ow&quot;&gt;not&lt;/span&gt;  &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;stopwords_list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;filtered_text&lt;/span&gt;  &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;  &lt;span class=&quot;s&quot;&gt;'  '&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;join&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;filtered_tokens&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;filtered_text&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;special-characters-and-number-removal&quot;&gt;Special characters and number removal.&lt;/h3&gt;

&lt;p&gt;Special characters and symbols are usually non-alphanumeric or occasionally numeric characters which add extra noise in unstructured text. For our problem, since our corpus is built with articles from the biomedical field, there are a lot of numbers denoting quantities and dosages. We have decided to remove them to simplify the tutorial.&lt;/p&gt;

&lt;h3 id=&quot;lematization&quot;&gt;Lematization&lt;/h3&gt;

&lt;p&gt;In this step, we will use lemmatization instead of stemming,&lt;/p&gt;

&lt;p&gt;Chirstopher Maning define lemmatization as :&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Lemmatization usually refers to doing things properly with the use of a vocabulary and morphological analysis of words, normally aiming to remove inflectional endings only and to return the base or dictionary form of a word, which is known as the lemma . If confronted with the token saw, stemming might return just s, whereas lemmatization would attempt to return either see or saw depending on whether the use of the token was as a verb or a noun. The two may also differ in that stemming most commonly collapses derivationally related words, whereas lemmatization commonly only collapses the different inflectional forms of a lemma.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;A good lemmatizer will replace words such as foot by feet; chosen, choose, by choice.; etc.&lt;/p&gt;

&lt;p&gt;This approach has some advantages because it will help not spread the information between different word forms derived from the same lemma. Therefore, it will lead to an accurate TF-IDF because the same semantic information is assembled in one place.&lt;/p&gt;

&lt;p&gt;The code for lemmatization is as follow :&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt;  &lt;span class=&quot;nf&quot;&gt;lemmatize_text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;text&lt;/span&gt;  &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;nlp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;text&lt;/span&gt;  &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;  &lt;span class=&quot;s&quot;&gt;'  '&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;join&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;word&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lemma_&lt;/span&gt;  &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;word&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lemma_&lt;/span&gt;  &lt;span class=&quot;o&quot;&gt;!=&lt;/span&gt;  &lt;span class=&quot;s&quot;&gt;'-PRON-'&lt;/span&gt;  &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;word&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;text&lt;/span&gt;  &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;word&lt;/span&gt;  &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;text&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Finally, we apply the preprocessing function to our dataset to generate a cleaned version for each abstract.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;preprocess_text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;text_lower_case&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;text_lemmatization&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stopword_removal&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;  
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;text_lower_case&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;text&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lower&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;strip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    
    &lt;span class=&quot;n&quot;&gt;text&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;re&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sub&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'[^\w\s]'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;''&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;text&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;re&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sub&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'[\r|\n|\r\n]+'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;' '&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;text&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;re&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sub&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'\d+'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;''&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;text_lemmatization&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;text&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lemmatize_text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;text&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;re&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sub&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;' +'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;' '&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# remove stopwords
&lt;/span&gt;    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stopword_removal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;text&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;remove_stopwords&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;is_lower_case&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;text_lower_case&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;text&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;data_df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'abstract_cleaned'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;  &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;data_df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'abstract'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;apply&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;preprocess_text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;With our text cleaned, we can move to our tutorial’s next section, which generates the most relevant keywords for each abstract.&lt;/p&gt;

&lt;h3 id=&quot;keyword-generation-using-term-inverse---document-frequency-tf-idf&quot;&gt;Keyword Generation using Term Inverse - Document Frequency (Tf-IDF)&lt;/h3&gt;

&lt;p&gt;To generate keywords for each paper, we have to find a heuristic that finds the most relevant words while penalizing the common phrase in our corpus. Practitioners have widely used the Term Frequency-Inverse Document Frequency (TF-IDF) to generate important keywords in documents in Information Retrieval. But what is TF-IDF? It combines two metrics, the Term frequency and the Inverse Document Frequency.&lt;/p&gt;

&lt;h4 id=&quot;term-frequency&quot;&gt;Term Frequency&lt;/h4&gt;

&lt;p&gt;[K. Sparck Jones.] defines the term frequency (TF) as a numerical statistic that reflects how important a word is to document in a collection or a corpus. It is the relative frequency of term w within the document d.&lt;/p&gt;

&lt;p&gt;It is computed  using the following formula :&lt;/p&gt;

\[\begin{equation}
    tf(w,d) = \frac{f_{w,d}}{\sum_{t\ast}^{d}f_{w\ast,d}}
\end{equation}\]

&lt;p&gt;with \(f_{w,d}\) defined as the raw count of the word w in the document d, and \(\sum_{t\ast}^{d}f_{w\ast,d}\) as the total number of terms in document d (counting each occurrence of the same term separately).&lt;/p&gt;

&lt;h4 id=&quot;inverse-document-frequency&quot;&gt;Inverse Document Frequency&lt;/h4&gt;

&lt;p&gt;The inverse document frequency is defined as the log of the ratio between the total number of documents in the 
corpus and the number of documents with the word. It is a measure the amount of information provided by the word.
\(\begin{equation}
    idf(w, d) = log\frac{N}{1 + (\left | d \in D : w \in d \right |)}
\end{equation}\)
with&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;N: total number of documents in the corpus N  and the  denominator represent the number of documents with the word w.
This helps to penalize the most common word in a corpus. Those words carry fewer values for in the corpus.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;For the curious who want to know why we use the log in the IDF, check out &lt;a href=&quot;https://stackoverflow.com/a/33429876/4683950&quot;&gt;this answer&lt;/a&gt; from StackOverflow.&lt;/p&gt;

&lt;p&gt;The TF-IDF combines both the Term Frequency and the Inverse Document Frequency.&lt;/p&gt;

\[(tf_idf)_{t,d} = Idf_t * TF_{w, d}\]

&lt;h4 id=&quot;applying-tf-idf-to-our-corpus&quot;&gt;Applying TF-IDF to our corpus&lt;/h4&gt;

&lt;p&gt;To apply TF-IDF we will leverage the sklearn implementation of the algorithm.
Before running the bellow code, make sure you have &lt;a href=&quot;https://scikit-learn.org/stable/about.html&quot;&gt;sklearn&lt;/a&gt; installed.&lt;/p&gt;

&lt;p&gt;If the sklearn is installed, you can import it with the bellow code.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt;  &lt;span class=&quot;nn&quot;&gt;sklearn.feature_extraction.text&lt;/span&gt;  &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;TfidfVectorizer&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;create_tfidf_features&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;corpus&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;max_features&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;max_df&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.95&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;min_df&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;&quot;&quot;&quot; Creates a tf-idf matrix for the `corpus` using sklearn. &quot;&quot;&quot;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;tfidf_vectorizor&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;TfidfVectorizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;decode_error&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'replace'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;strip_accents&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'unicode'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;analyzer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'word'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
                                       &lt;span class=&quot;n&quot;&gt;stop_words&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'english'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ngram_range&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;max_features&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;max_features&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
                                       &lt;span class=&quot;n&quot;&gt;norm&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'l2'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;use_idf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;smooth_idf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sublinear_tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                                       &lt;span class=&quot;n&quot;&gt;max_df&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;max_df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;min_df&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;min_df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tfidf_vectorizor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fit_transform&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;corpus&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'tfidf matrix successfully created.'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tfidf_vectorizor&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&lt;a href=&quot;https://melaniewalsh.github.io/Intro-Cultural-Analytics/05-Text-Analysis/03-TF-IDF-Scikit-Learn.html&quot;&gt;This article&lt;/a&gt; recommended  to use  &lt;code class=&quot;language-bash highlighter-rouge&quot;&gt;TfidfVectorizer&lt;/code&gt;  with smoothing (&lt;code class=&quot;language-bash highlighter-rouge&quot;&gt;smooth_idf  &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;  True&lt;/code&gt;) and normalization (&lt;code class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;span class=&quot;nv&quot;&gt;norm&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'l2&quot;) turned on. These parameters will better account for text length differences and produce more meaningful to–IDF scores. Smoothing and L2 normalization are the default settings for &lt;/span&gt;&lt;/code&gt;TfidfVectorizer,` so you don’t need to include any extra code at all to turn them on.&lt;/p&gt;

&lt;p&gt;On top of the &lt;code class=&quot;language-bash highlighter-rouge&quot;&gt;smoth_idf&lt;/code&gt;  and &lt;code class=&quot;language-bash highlighter-rouge&quot;&gt;norm&lt;/code&gt; hyperparameters, the other keys hyperparameters are :&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;language-bash highlighter-rouge&quot;&gt;max_features&lt;/code&gt; which denotes the max number of words to keep in our vocabulary&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-bash highlighter-rouge&quot;&gt;max_df&lt;/code&gt;: When building the vocabulary, ignore terms that have a document frequency strictly higher than the given threshold&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-bash highlighter-rouge&quot;&gt;min_df:&lt;/code&gt; When building the vocabulary, ignore terms that have a document frequency strictly lower than the given threshold. This value is also called a cut-off in the literature.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-bash highlighter-rouge&quot;&gt;n_gram_range&lt;/code&gt; is the number of n-grams to consider when building our vocabulary; for this task, we consider nonograms, bigrams, and trigrams.&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;data_df&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data_df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reset_index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;tf_idf_matrix&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf_idf_vectorizer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;create_tfidf_features&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data_df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'abstract_cleaned'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;After applying the tf_if vectorizer on to our corpus, it will result in the following two objects :&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;The &lt;code class=&quot;language-bash highlighter-rouge&quot;&gt;tf_ifd matrix&lt;/code&gt; , is a matrix where rows are the documents and columns are the words in our vocabulary.&lt;/li&gt;
  &lt;li&gt;The &lt;code class=&quot;language-bash highlighter-rouge&quot;&gt;tf_idf_vectorizer&lt;/code&gt; is an object that will help us to transform a new document to the TF-IDF version.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The value at the ith row and jth column is the TF-IDF score of the word j in document i.&lt;/p&gt;

&lt;p&gt;For better analysis we converted the &lt;code class=&quot;language-bash highlighter-rouge&quot;&gt;tf_idf_matrix&lt;/code&gt; into a pandas dataframe using the following code :&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;tfidf_df&lt;/span&gt;  &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DataFrame&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tf_idf_matrix&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;toarray&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;columns&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tf_idf_vectorizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get_feature_names&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;index&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data_df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The next step is to generate the top 20 keywords for each document, those word are the word with the highest tf-idf score within the document.&lt;/p&gt;

&lt;p&gt;Before doing that, let’s reorganize the DataFrame so that the words are in rows rather than columns.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;tfidf_df&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tfidf_df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sort_index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;round&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;decimals&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;tfidf_df_stacked&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tfidf_df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;stack&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reset_index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;tfidf_df_stacked&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tfidf_df_stacked&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rename&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;columns&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'tfidf'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'level_1'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'term'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;level_0&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;doc_id&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;})&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;We sort by document and tfidf score and then groupby document and take the first 20 values.
Once we have sorted and find the top keywords we can save them in a dictionary where the keys are the the document id and the values are the another dictionary of the term and their tf-idf score.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;tfidf_df_stacked&lt;/span&gt;  &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;tfidf_df_stacked&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reset_index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rename&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;columns&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'level_1'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'term'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;})&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;document_tfidf&lt;/span&gt;  &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;tfidf_df_stacked&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;groupby&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'doc_id'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]).&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;apply&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;lambda&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'term'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;  &lt;span class=&quot;s&quot;&gt;&quot;tfidf&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]].&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;set_index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;term&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;to_dict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'tfidf'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;With our documents and the top keyword mappings, we can now visualize what our corpus looks like to have an idea on each paper on the document.&lt;/p&gt;

&lt;p&gt;I recently come across a good piece of code that makes visualization for a document using TF-IDF.&lt;/p&gt;

&lt;p&gt;I grabbed it from this &lt;a href=&quot;https://melaniewalsh.github.io/Intro-Cultural-Analytics/05-Text-Analysis/03-TF-IDF-Scikit-Learn.html&quot;&gt;article&lt;/a&gt;.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;altair&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;alt&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Terms in this list will get a red dot in the visualization
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;term_list&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;covid&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'traitement'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'ebola'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# adding a little randomness to break ties in term ranking
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;top_tfidf_plusRand&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tfidf_df_stacked&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;800&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;top_tfidf_plusRand&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'tfidf'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;top_tfidf_plusRand&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'tfidf'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rand&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tfidf_df_stacked&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;800&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.0001&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# base for all visualizations, with rank calculation
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;base&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;alt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Chart&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;top_tfidf_plusRand&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;encode&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'rank:O'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'doc_id:N'&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;transform_window&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;rank&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;rank()&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;sort&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;alt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;SortField&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;tfidf&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;order&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;descending&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)],&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;groupby&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;doc_id&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# heatmap specification
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;heatmap&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;base&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mark_rect&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;encode&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;color&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'tfidf:Q'&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# red circle over terms in above list
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;circle&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;base&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mark_circle&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;encode&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;color&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;alt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;condition&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;alt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;FieldOneOfPredicate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;field&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'term'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;oneOf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;term_list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;alt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'red'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;alt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'#FFFFFF00'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;        
    &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# text labels, white for darker heatmap colors
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;text&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;base&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mark_text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;baseline&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'middle'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;encode&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;text&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'term:N'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;color&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;alt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;condition&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;alt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;datum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tfidf&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.23&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;alt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'white'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;alt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'black'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# display the three superimposed visualizations
&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;heatmap&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;circle&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;properties&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;width&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1200&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;figure&gt;
  &lt;p&gt;&lt;img src=&quot;/assets/posts/2022-04-07-information-retrieval-on-medical-research-papers-about-covid19/tf-idf-chart.png&quot; /&gt;&lt;/p&gt;
  &lt;figcaption&gt;each document and top 10 terms&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;h4 id=&quot;querying-using-tf-idf&quot;&gt;Querying using tf-idf&lt;/h4&gt;

&lt;figure&gt;
  &lt;p&gt;&lt;img src=&quot;/assets/posts/2022-04-07-information-retrieval-on-medical-research-papers-about-covid19/query-processing-tfidf.png&quot; /&gt;&lt;/p&gt;
  &lt;figcaption&gt;The text Processing Part&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;With our TF-IDF we could easily use it to run search and make queries that use the TF-IDF score and cosine similarty.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;sklearn.metrics.pairwise&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cosine_similarity&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;calculate_similarity&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;query&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tf_idf_matrix&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vectorizor&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tf_idf_vectorizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;top_k&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;&quot;&quot;&quot; Vectorizes the `query` via `vectorizor` and calculates the cosine similarity of
    the `query` and `X` (all the documents) and returns the `top_k` similar documents.
    &quot;&quot;&quot;&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# Vectorize the query to the same length as documents
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;query_vec&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vectorizor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;transform&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;query&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# Compute the cosine similarity between query_vec and all the documents
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;cosine_similarities&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cosine_similarity&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;query_vec&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;flatten&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# Sort the similar documents from the most similar to less similar and return the indices
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;most_similar_doc_indices&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;argsort&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cosine_similarities&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)[:&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;top_k&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;most_similar_doc_indices&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cosine_similarities&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;show_similar_documents&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cosine_similarities&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;similar_doc_indices&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;&quot;&quot;&quot; Prints the most similar documents using indices in the `similar_doc_indices` vector.&quot;&quot;&quot;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;counter&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;index&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;similar_doc_indices&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'Top-{}, Similarity = {}'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;format&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;counter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cosine_similarities&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;pubmed_id&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'pubmed_id'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'the pubmed id : {}, '&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;format&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pubmed_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'title {}'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;format&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data_df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;title&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;abstract {}&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;format&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data_df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;abstract&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;50&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;counter&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'**=='&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The above code, get our new query, generate it TF-IDF  vector. Then it computes the cosine similarity between the vectors and all our documents in the TF-IDF matrix.&lt;/p&gt;

&lt;p&gt;As the result, it returns the top n rows in the matrix which are similar to our query vector.&lt;/p&gt;

&lt;p&gt;Let us try to check how it works in practice.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;time&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;query&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'are gorillas responsible of ebola'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;search_start&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;time&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;time&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;sim_vecs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cosine_similarities&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;calculate_similarity&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;query&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;search_time&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;time&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;time&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;search_start&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;search time: {:.2f} ms&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;format&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;search_time&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;show_similar_documents&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data_df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cosine_similarities&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sim_vecs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;search &lt;span class=&quot;nb&quot;&gt;time&lt;/span&gt;: 7.60 ms

Top-1, Similarity &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; 0.25484833157402037
the pubmed &lt;span class=&quot;nb&quot;&gt;id&lt;/span&gt; : 32287784, 
title Wuhan virus spreads
abstract We now know the virus responsible &lt;span class=&quot;k&quot;&gt;for &lt;/span&gt;deaths and i
&lt;span class=&quot;k&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;==&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;==&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;==&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;==&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;==&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;==&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;==&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;==&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;==&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;==&lt;/span&gt;
Top-2, Similarity &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; 0.2332808978421972
the pubmed &lt;span class=&quot;nb&quot;&gt;id&lt;/span&gt; : 32162604, 
title How Is the World Responding to the Novel Coronavirus Disease &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;COVID-19&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; Compared with the 2014 West African Ebola Epidemic? The Importance of China as a Player &lt;span class=&quot;k&quot;&gt;in &lt;/span&gt;the Global Economy
abstract This article describes similarities and difference
&lt;span class=&quot;k&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;==&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;==&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;==&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;==&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;==&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;==&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;==&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;==&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;==&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;==&lt;/span&gt;
Top-3, Similarity &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; 0.1286925639778678
the pubmed &lt;span class=&quot;nb&quot;&gt;id&lt;/span&gt; : 19297495, 
title Aquareovirus effects syncytiogenesis by using a novel member of the FAST protein family translated from a noncanonical translation start site.
abstract As nonenveloped viruses, the aquareoviruses and or
&lt;span class=&quot;k&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;==&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;==&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;==&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;==&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;==&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;==&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;==&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;==&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;==&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;==&lt;/span&gt;
Top-4, Similarity &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; 0.11561157619559267
the pubmed &lt;span class=&quot;nb&quot;&gt;id&lt;/span&gt; : 27325914, 
title Consortia critical role &lt;span class=&quot;k&quot;&gt;in &lt;/span&gt;developing medical countermeasures &lt;span class=&quot;k&quot;&gt;for &lt;/span&gt;re-emerging viral infections: a USA perspective.
abstract Viral infections, such as Ebola, severe acute resp
&lt;span class=&quot;k&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;==&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;==&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;==&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;==&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;==&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;==&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;==&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;==&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;==&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;==&lt;/span&gt;
Top-5, Similarity &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; 0.10755790364315998
the pubmed &lt;span class=&quot;nb&quot;&gt;id&lt;/span&gt; : 33360484, 
title Neuropathological explanation of minimal COVID-19 infection rate &lt;span class=&quot;k&quot;&gt;in &lt;/span&gt;newborns, infants and children – a mystery so far. New insight into the role of Substance P
abstract Sars-Cov-2 or Novel coronavirus infection &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;COVID-1
&lt;span class=&quot;k&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;==&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;==&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;==&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;==&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;==&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;==&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;==&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;==&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;==&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;==&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;That is all for the first part of this tutorial , We have learned how to build TF-IDF vectors, and how to leverage the cosine similarity to compute and retrieve documents that matches a query. In the second part of the tutorial we will learn how to use elasticsearch to perform the same task.&lt;/p&gt;
</description>
        <pubDate>Thu, 07 Apr 2022 13:03:59 +0100</pubDate>
        <link>http://localhost:4000/information-retrieval-on-medical-research-papers-about-covid19</link>
        <guid isPermaLink="true">http://localhost:4000/information-retrieval-on-medical-research-papers-about-covid19</guid>
        
        <category>python,</category>
        
        <category>information-retrieval,</category>
        
        <category>elastic-search,</category>
        
        <category>covid19,</category>
        
        <category>cord-19</category>
        
        
      </item>
    
      <item>
        <title>Congolese 🇨🇩 , Africans young Software Engineers, and Computer Scientists graduates - let’s get that master's degree! 🚀 🚀🚀🎓</title>
        <description>
&lt;figure&gt;
  &lt;p&gt;&lt;img src=&quot;/assets/posts/2022-04-06-master-options-africans/cmu-africa-graduation.png&quot; /&gt;&lt;/p&gt;
  &lt;figcaption&gt;CMU Africa Graduation ceremony class of 2019, I need someone to put the 🇨🇩 on that picture next time&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;I had been dreaming about attending a high-ranked university for ages. The interaction with brilliant professors, lecturers, the smell of old books in a library, and the social aspect of university life have always fascinated me.&lt;/p&gt;

&lt;p&gt;After graduating from my local university in my native country - Congo, I decided to gain some real-world experience by working instead of going straight for a master’s degree. Six years passed since I graduated, and I yearned to build a strong career in the Software Engineering industry. I wanted to realize my dream, and I decided to apply for a Master in Data Science in the UK. Fortunately, I got an offer from the University of Essex, thanks for the Chevening Scholarship. For those who don’t know I am currently doing my master at that university, my experience about it are mixed but that is out of the scope of this blog  🤪.&lt;/p&gt;

&lt;p&gt;As a Software Engineer, there are different ways to learn. I have gone through all of them:  tutorials, coding Bootcamp, Youtube videos, MOOC, personnel projects, and the academic way. Nevertheless, I can attest, that as long as we live in today’s world and economy, a &lt;strong&gt;high-ranked&lt;/strong&gt; university is still the best, the most legit, and the most credible way to learn and acquire new skills, especially when it comes to research. I am not opening the old debate on the best way to learn as a Software Engineer, and it is beyond the scope of this blog. Instead, I will share some opportunities for young talented graduates from the continent in general and DRCongo particularly, on attending high-ranked universities globally.&lt;/p&gt;

&lt;p&gt;As a young African growing up in DRCongo, there are fewer options for good universities than someone born and raised in Europe or North America.&lt;/p&gt;

&lt;p&gt;Fortunately, there have been initiatives to improve inclusivity for people from developing countries or of disadvantaged backgrounds in academia over the past decade.&lt;/p&gt;

&lt;p&gt;Following up on a recent discussion with an old friend of mine in a WhatsApp group, I decided to put some options young graduates with a similar background as me can access  to get a good master’s in computer science or related field.&lt;/p&gt;

&lt;p&gt;I will talk about some of them below, and the list is not exhaustive. In conclusion, I will share some of my tips to get opportunities in my career.&lt;/p&gt;

&lt;h2 id=&quot;carnegie-mellon-university--africa&quot;&gt;&lt;a href=&quot;https://www.cmu.edu/africa/&quot;&gt;Carnegie Mellon University  AFRICA&lt;/a&gt;&lt;/h2&gt;

&lt;figure&gt;
  &lt;p&gt;&lt;img src=&quot;/assets/posts/2022-04-06-master-options-africans/cmu-africa-campus.jpeg&quot; /&gt;&lt;/p&gt;
  &lt;figcaption&gt;CMU Africa campus, I am sure there are some Europeans universities campuses which are not as beautiful as this campus&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;The CMU Africa is an extension of the main &lt;a href=&quot;https://www.cmu.edu/&quot;&gt;CMU,&lt;/a&gt; which is one of the best computer science universities in the world. In 2011, following up on a recent partnership with the (African Bank of Development)BAD and the World Bank, CMU has decided to open its door in Rwanda to bring high-quality education to Africa. It is the only U.S. research university offering its master’s degrees with a full-time faculty, staff, and operations in Africa.&lt;/p&gt;

&lt;p&gt;Since 2018, I have been interacting with CMU graduates from all over Africa. I can attest it is one of the best masters out there. CMU is the pillar of the Rwanda and East African tech scene. Their graduates are working for top-notch tech companies locally. Some of my CMU Alumni friends are working for Google, IBM, or doing Ph.D. in the main CMU campus or Oxford.&lt;/p&gt;

&lt;p&gt;Here are some of the alumni from the university I got a chance to interact with :&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.linkedin.com/in/kesaoluwafunmilola/&quot;&gt;Oluwafunmilola Kesa&lt;/a&gt;, Software Engineer at Microsoft, Vancouver Canada&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.cs.ox.ac.uk/people/daniel.omeiza/&quot;&gt;Daniel Omeiza&lt;/a&gt;, Ph.D. Student at University of Oxford, Oxford UK&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://ng.linkedin.com/in/azeez-oluwafemi&quot;&gt;Azeez Oluwafemi&lt;/a&gt;, Research Engineer at Borealis AI, Vancouver Canada.&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://ug.linkedin.com/in/joan-kirunga&quot;&gt;Joan Kirunga&lt;/a&gt; , Senior Data Scientist at BBox, Kigali Rwanda&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.linkedin.com/in/victorakinwande/&quot;&gt;Victor Akinwande&lt;/a&gt;, Phd Student, at the main CMU in Pennsylvania, USA&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;what-are-the-costs&quot;&gt;What are the costs:&lt;/h3&gt;

&lt;p&gt;I have met some students who got scholarships from the Rwandan government if they are Rwandans or the &lt;a href=&quot;https://www.africa.engineering.cmu.edu/impact/mastercard-scholars.html&quot;&gt;prestigious Mastercard Scholarship.&lt;/a&gt; According to &lt;a href=&quot;https://www.africa.engineering.cmu.edu/admissions/tuition/index.html&quot;&gt;their website,&lt;/a&gt; the tuition fees can range from 8k to 16k USD per year. If you have a good track of leadership and community-building experience, you can easily find a scholarship that funds your studies at CMU Africa.&lt;/p&gt;

&lt;h2 id=&quot;africa-master-of-machine-intelligence&quot;&gt;&lt;a href=&quot;https://aimsammi.org/&quot;&gt;Africa Master of Machine Intelligence&lt;/a&gt;&lt;/h2&gt;

&lt;figure&gt;
  &lt;p&gt;&lt;img src=&quot;/assets/posts/2022-04-06-master-options-africans/ammi-launch-8.jpeg&quot; /&gt;&lt;/p&gt;
  &lt;figcaption&gt;AMMI Kigali launch&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;In 2019, with a partnership with Google and Facebook, &lt;a href=&quot;https://medium.com/@moustaphacisse/introducing-the-african-masters-of-machine-intelligence-at-aims-9441b4346a55&quot;&gt;Moustapha Cisse launched&lt;/a&gt; the African Master of Machine Intelligence.&lt;/p&gt;

&lt;p&gt;AMMI is a one-year master’s to help passionate young Africans access cutting-edge research on Artificial Intelligence without leaving the country and going through the hassle of a student visa. I have seen top researchers from (University College of London) UCL or Google lecturing at the university. In 2019, I had a chance to meet &lt;a href=&quot;https://deisenroth.cc/&quot;&gt;Marc Peter Deisenroth&lt;/a&gt;, who was lecturing at the university. He wrote one of the best books on &lt;a href=&quot;https://books.google.co.uk/books?id=pbONxAEACAAJ&amp;amp;printsec=frontcover&amp;amp;source=gbs_ge_summary_r&amp;amp;cad=0#v=onepage&amp;amp;q&amp;amp;f=false&quot;&gt;Mathematic of Machine Learning.&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;The final goal of the university is to produce talent for the Google office in Accra. I can attest I know some of their graduates who joined the Google Accra office and are doing well. I also know others who went for Ph.D. in top universities in Europe.&lt;/p&gt;

&lt;p&gt;Here are some alums from Congo I had a chance to interact with :&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://aimsammi.org/person/muhigiri-cirhuza-alain/&quot;&gt;Muhigiri Chiruza Alain&lt;/a&gt;, The guy is one of those smart people who don’t have an online profile, I am sure he is doing well, maybe doing a Ph.D. at Standford or somewhere.&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.linkedin.com/in/salomon-kabongo&quot;&gt;Salomon Kabongo&lt;/a&gt;, Phd Student at L3S Research, Leipzig Germany&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;what-are-the-costs-&quot;&gt;What are the costs :&lt;/h3&gt;

&lt;p&gt;The program is highly competitive and only takes the best talent. Its acceptance rate, which is six percent, makes it one of the most prestigious masters in Africa. Fortunately, it is free; Google and Facebook cover your tuition fees. If you are one of those guys who could quickly get 72 % in undergrad, you have a solid background in Mathematics and Computer Science, and you are passionate about Machine Learning, you should give this program a try.&lt;/p&gt;

&lt;h2 id=&quot;chevening-scholarship&quot;&gt;&lt;a href=&quot;https://www.chevening.org/&quot;&gt;Chevening scholarship.&lt;/a&gt;&lt;/h2&gt;

&lt;figure&gt;
  &lt;p&gt;&lt;img src=&quot;/assets/posts/2022-04-06-master-options-africans/chevener-from-drc.jpeg&quot; /&gt;&lt;/p&gt;
  &lt;figcaption&gt;Chevener from DRC 2022 cohort , caption me if you can 🤪 &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;The program has been there for more than 30 years and provides African leaders the chance to study at any British university of their choice fully funded. Suppose you manage to get a place in one of the best UK universities for Machine Learning or Data Science, Chevening will cover your tuition fees.&lt;/p&gt;

&lt;p&gt;I can guarantee, that if you have dreamt about studying at one of the best British Universities, you can try this scholarship. As a Chevening scholar, I can attest that this is one of the best scholarships you can get if you are admitted to a good university. It gives you access to a good network of computer scientists and people from different backgrounds.&lt;/p&gt;

&lt;p&gt;Chevening alumni are currently among the best leaders in their respective countries.&lt;/p&gt;

&lt;p&gt;Some Alums I have interacted with :&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://www.linkedin.com/in/mbithenzomo/&quot;&gt;Mbithe Nzomo&lt;/a&gt;, Doctoral Researcher, University of Cape Town, South Africa&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;And the list goes on, there handful of Cheveners who did Computer Science and are doing well in life. Head to &lt;a href=&quot;https://www.chevening.org/alumni/&quot;&gt;this link&lt;/a&gt; to learn more about them.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;what-are-the-costs--1&quot;&gt;What are the costs :&lt;/h3&gt;

&lt;p&gt;It is a fully-funded scholarship, and you don’t need to pay anything. You are only required to have two years of work experience and good leadership background. As part of the application process, you will have to write four essays. These are your leadership and Networking skills, your course of studies, and your career plan. The application process is lengthy, but it is worth it. To be honest with you, it is one of the best scholarships in the world as long as you get a place to a good university in UK. One quack, is that part of the terms and conditions of the scholarship you have to return to your home country for at least two years.&lt;/p&gt;

&lt;h2 id=&quot;conclusions&quot;&gt;Conclusions&lt;/h2&gt;

&lt;p&gt;Those are the top three programs any African Engineer who wants to go for a master’s in Computer science can think about. The list is not exhaustive; there are more programs out there, especially South African universities. I am still collecting information about them.
Should I get more time and energy in the future, I will post them in part two of this series. I will share more advice on how to get access to top research papers in the world without attending a university. Additionally, I will share some undergraduate universities you can dream about.
Until my next feature, stay safe, take care, and see you in part two of this series.&lt;/p&gt;
</description>
        <pubDate>Wed, 06 Apr 2022 11:22:56 +0100</pubDate>
        <link>http://localhost:4000/master-options-africans</link>
        <guid isPermaLink="true">http://localhost:4000/master-options-africans</guid>
        
        
        <category>non-tech</category>
        
      </item>
    
      <item>
        <title>install nvidia driver</title>
        <description>&lt;p&gt;I had many driver installed I my virtual machine , so It was actually the reason why I was having the error.&lt;/p&gt;

&lt;p&gt;To fix it I had first to remove all driver I have installed before using :&lt;/p&gt;

&lt;p&gt;-&lt;code class=&quot;language-clojure highlight highlighter-rouge&quot;&gt;&lt;span class=&quot;n&quot;&gt;sudo&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;apt-get&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;purge&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nvidia-*&lt;/span&gt;&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;-&lt;code class=&quot;language-clojure highlight highlighter-rouge&quot;&gt;&lt;span class=&quot;n&quot;&gt;sudo&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;apt-get&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;update&lt;/span&gt;&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;-&lt;code class=&quot;language-clojure highlight highlighter-rouge&quot;&gt;&lt;span class=&quot;n&quot;&gt;sudo&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;apt-get&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;autoremove&lt;/span&gt;&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;After that I when a head and installed the latest version of it nvidia driver:&lt;/p&gt;

&lt;p&gt;I did :&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;language-clojure highlight highlighter-rouge&quot;&gt;&lt;span class=&quot;n&quot;&gt;apt&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;search&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nvidia-driver&lt;/span&gt;&lt;/code&gt; 
To get the latest version of the driver
After getting the latest version I installed it with :&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Edit Sept 2021 : According to the last comment  by @a-r-j  you can install a couple of dependencies before&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;language-clojure highlight highlighter-rouge&quot;&gt;&lt;span class=&quot;n&quot;&gt;sudo&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;apt&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;install&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;libnvidia-common-470&lt;/span&gt;&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-clojure highlight highlighter-rouge&quot;&gt;&lt;span class=&quot;n&quot;&gt;sudo&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;apt&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;install&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;libnividia-gl-470&lt;/span&gt;&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Then you can move forward and install the driver.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;language-clojure highlight highlighter-rouge&quot;&gt;&lt;span class=&quot;n&quot;&gt;sudo&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;apt&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;install&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nvidia-driver-470&lt;/span&gt;&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;And after installing it I rebooted my machine and checked with :&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;language-clojure highlight highlighter-rouge&quot;&gt;&lt;span class=&quot;n&quot;&gt;nvidia-smi&lt;/span&gt;&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;And tata ☄️&lt;/p&gt;

&lt;p&gt;The results :&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://imgur.com/a/xfpvrtb.jpg&quot; alt=&quot;Imgur Image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Ressources :&lt;/p&gt;

&lt;p&gt;https://www.cyberciti.biz/faq/ubuntu-linux-install-nvidia-driver-latest-proprietary-driver/&lt;/p&gt;

</description>
        <pubDate>Sun, 27 Mar 2022 14:36:01 +0100</pubDate>
        <link>http://localhost:4000/install-nvidia-driver</link>
        <guid isPermaLink="true">http://localhost:4000/install-nvidia-driver</guid>
        
        
      </item>
    
      <item>
        <title>Local Boy visited the Etihad Stadium. Here is how it went.</title>
        <description>
&lt;figure&gt;
  &lt;p&gt;&lt;img src=&quot;/assets/posts/2021-12-27-local-boy-visited-the-etihad-stadium-here-is-how-it-went/dream-come-true.jpeg&quot; /&gt;&lt;/p&gt;
  &lt;figcaption&gt;dream come true&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;I had been dreaming about visiting the Etihad Stadium one day in my life. When I first applied for the Chevening Scholarship, watching a Mancity game was one of the reasons why I wanted to come to the UK.&lt;/p&gt;

&lt;p&gt;I knew Boxing Day was a big day for the English Premier League, which is why I booked my ticket for the Manchester City against Leicester Game despite fear of postponement due to the new variant of COVID.&lt;/p&gt;

&lt;p&gt;I traveled from Colchester to Manchester on the 24th of December and, I booked my stay at the Britannica Hotel in the heart of Manchester Piccadilly.&lt;/p&gt;

&lt;p&gt;On the day of the game,  I took the bus to the Stadium. At first glimpse of the Stadium, I was in tears. My childhood dream became a reality. I was at the Etihad Stadium.&lt;/p&gt;

&lt;p&gt;I arrived a bit late and missed the chance to have a full official Stadium tour. I still managed to visit the Stadium by myself later on, and took some nice pictures.&lt;/p&gt;

&lt;h3 id=&quot;meeting-the-legend&quot;&gt;Meeting the legend&lt;/h3&gt;

&lt;p&gt;Firstly, let’s start with a bit of history. I have been supporting Manchester City since 2008 when I found that Vincent Kompany has some Congolese origin and comes from the same region as I. I wish I had the chance to meet him when he played for ManCity, but sadly he retired from professional football years ago.&lt;/p&gt;

&lt;p&gt;I have been a massive fan of him for his leadership on and off the pitch. I consider him my role model; therefore, I had to take my first picture of the day with his statue.&lt;/p&gt;

&lt;figure&gt;
  &lt;p&gt;&lt;img src=&quot;/assets/posts/2021-12-27-local-boy-visited-the-etihad-stadium-here-is-how-it-went/meeting-the-legend.jpeg&quot; /&gt;&lt;/p&gt;
  &lt;figcaption&gt;legend&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;h3 id=&quot;the-dream-come-true&quot;&gt;The Dream come true&lt;/h3&gt;

&lt;p&gt;Secondly, I went to the Stadium and took the picture that sums up my childhood dreams, Espoir in the UK.&lt;/p&gt;

&lt;figure&gt;
  &lt;p&gt;&lt;img src=&quot;/assets/posts/2021-12-27-local-boy-visited-the-etihad-stadium-here-is-how-it-went/etihad-stadium.jpeg&quot; /&gt;&lt;/p&gt;
  &lt;figcaption&gt;at Stadium&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;h3 id=&quot;cream-on-the-cake-i-watched-a-game-live&quot;&gt;Cream on the cake, I watched a game live.&lt;/h3&gt;

&lt;p&gt;And Finally, before the game, I took another one to show people and everyone I have been watching football with in Goma, Bukavu, Kigali pubs that their friend and the only Manchester City fan they know has made it to the Stadium.&lt;/p&gt;

&lt;figure&gt;
  &lt;p&gt;&lt;img src=&quot;/assets/posts/2021-12-27-local-boy-visited-the-etihad-stadium-here-is-how-it-went/before-game.jpeg&quot; /&gt;&lt;/p&gt;
  &lt;figcaption&gt;before the game&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;h3 id=&quot;final-result-and-fpl-disappointments&quot;&gt;Final result and FPL disappointments&lt;/h3&gt;

&lt;p&gt;The game did end up well; we won 6-3; unfortunately, my FPL captain Phil Foden got only one point. I think this is the old FPL course. You_ should not captain a player you will be watching live. _&lt;/p&gt;

&lt;figure&gt;
  &lt;p&gt;&lt;img src=&quot;/assets/posts/2021-12-27-local-boy-visited-the-etihad-stadium-here-is-how-it-went/fpl-team-result.jpeg&quot; /&gt;&lt;/p&gt;
  &lt;figcaption&gt;fpl team result&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;I wish I had the chance to catch the Canal + Broadcasting car to get a chance to pass on TV, but unfortunately, I couldn’t find where the car was standing.&lt;/p&gt;

&lt;p&gt;Now I can say that I finished my year in style. I hope to watch more games in the future and more importantly to catch the CANAL + car next time I visit the Stadium.&lt;/p&gt;

</description>
        <pubDate>Mon, 27 Dec 2021 18:20:39 +0000</pubDate>
        <link>http://localhost:4000/blog/2021/local-boy-visited-the-etihad-stadium-here-is-how-it-went/</link>
        <guid isPermaLink="true">http://localhost:4000/blog/2021/local-boy-visited-the-etihad-stadium-here-is-how-it-went/</guid>
        
        
        <category>non-tech</category>
        
      </item>
    
      <item>
        <title>Lessons learned while Applying to Master’s Degrees In the UK.</title>
        <description>&lt;p&gt;A bit earlier last year, in August 2020, I learned about the &lt;a href=&quot;https://www.chevening.org/&quot;&gt;Chevening scholarship&lt;/a&gt; from the Uk government, and I decided to give it a try. Chevening is a fully-funded scholarship by the UK government; it offers mid-career professionals from some countries the opportunity to study for a master’s degree in any university in the UK.&lt;/p&gt;

&lt;p&gt;Part of the conditions to get the scholarship is to gain entry to any UK University. As a result, Chevening will cover your tuition fees and give you a monthly stipend of 1150 pounds. I needed the scholarship and admission to a UK university, and that is how my journey started.&lt;/p&gt;

&lt;p&gt;In this blog, I will relate my experience with the application process. I will talk about my failures, my success stories, and what I learned during the process.&lt;/p&gt;

&lt;p&gt;But before talking about the universities, let me talk about myself and my background to give you more context.&lt;/p&gt;

&lt;h2 id=&quot;a-local-boy-from-bukavu-who-studied-in-goma&quot;&gt;A local boy from Bukavu who studied in Goma&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://lh5.googleusercontent.com/M1sxZv-WK7g0gK0ZnDlbeDh2SewMyBlXvD2M5gMXmu6OCQHLQYo5YAiMq-GMkWQGBe4CWu0vdWMrrPZ5Lubf5gG2CGbn1dztFiegOJR9HdsJ5THG34m_R5xm67fd9cTwbapETJ_7&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The younger me, after my first year of undergraduate, receiving a scholarship worth 120 USD&lt;/p&gt;

&lt;p&gt;I am from DR Congo, and I graduated from ULPGL in Goma, Eastern Congo; and as you may guess, I did my undergraduate studies in French. I did what we called Polytechnic and graduated in Genie Electrique et Informati­que, which is an equivalent of a Bachelor’s degree in Electrical Engineering and Computer science. As I spent six years in undergraduates studies, I thought it was a master’s degree, but I am sure it was not.&lt;/p&gt;

&lt;p&gt;I didn’t graduate with distinction despite finishing some years with 72 %. I finished my last year with 64%, which was not a distinction. On average, my grades were around 67% which was an equi­valent of 2:2 degree in the UK or second class.&lt;/p&gt;

&lt;p&gt;I think if I had the same grades in the UK , I would have been a first class degree. However since I came from a poor ranking country , the universities in the UK considered the degree  as second class. I learned this a bit late , but you can check the &lt;a href=&quot;https://www.westminster.ac.uk/sites/default/public-files/general-documents/overseas-academic-qualifications-equivalency-chart.pdf&quot;&gt;following article&lt;/a&gt; for the equivalences per country.&lt;/p&gt;

&lt;p&gt;On top of my undergraduate, I had around five years of experience as a software engineer. I also had some Machine Learning experience acquired via community work and personal projects. I got the chance to participate in a research paper that got published, &lt;a href=&quot;https://arxiv.org/abs/2003.11529&quot;&gt;Masakhane’s paper&lt;/a&gt;. By the time I was applying, I was working on another paper that was not yet published.&lt;/p&gt;

&lt;p&gt;My dream was to find a specialized master in Natural language processing or computational linguistic in the UK. That was my first mistake. Instead of looking for a specialized master in NLP, I could have looked for a more general master in either Machine learning, Data Science or Artificial Intelligence with NLP Courses.&lt;/p&gt;

&lt;h2 id=&quot;the-application-process&quot;&gt;The Application Process&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://lh6.googleusercontent.com/Sk5MSRpTRSYxLIfvDHzd5WDqRlHLWNUonEr7nXG0albajremxmTQC4kP6zPAQPHrn-lkf4gC5ztC8imUeIlxeiXI4p3eGyelVBE8ip8lE4efMYroUv7hBHYzUQ2ayYZQsB4zR7KC&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;the-ielts-tests&quot;&gt;The IELTS Tests&lt;/h2&gt;

&lt;p&gt;Coming from a francophone university I knew that it was important for me to have an English test either an IELTS or a TOEFL. I decide to go for the IELTS since I was applying for universities in the UK.&lt;/p&gt;

&lt;p&gt;I sat for the IELTS test back in November 2020, and I was glad to get a 6.5. That was the least score to gain admission to a top university in the UK for 2021-2022. To learn more about my IELTS experience, &lt;a href=&quot;https://murhabazi.com/ielts-how-it-went/&quot;&gt;check out this blog post&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;the-recommendation-letters&quot;&gt;The recommendation letters&lt;/h2&gt;

&lt;p&gt;I was glad and lucky with the recommendations I got. I didn’t leave my University on a good note, so it was not the best place to look for recommendations. However, I managed to get recommendations from my academic mentor from my research group, a former classmate who is already a Ph.D. student and a teaching assistant, and another one from a former colleague. There were generic recommendations where I needed to edit the university and the program I was applying for.&lt;/p&gt;

&lt;h2 id=&quot;my-universities-choices&quot;&gt;My Universities choices&lt;/h2&gt;

&lt;p&gt;As a guy who came from a low-tier university with poor grades, with strong imposter syndrome, and who was afraid to live in big cities; I didn’t bother applying to the top four: Oxbridge, UCL, Imperial, which are the top universities In Machine learning In the UK,In Europe and in the World.&lt;/p&gt;

&lt;p&gt;I went ahead as the first batch and applied to the speech and Natural language processing at Edinburgh and the same program at Sheffield and Artificial Intelligence at Cardiff University. But honestly speaking, they were decent programs.&lt;/p&gt;

&lt;h2 id=&quot;mistakes-i-made-while-applying&quot;&gt;Mistakes I made while applying.&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://lh3.googleusercontent.com/ebv42UX_vWcm20D0DMKyW_-PRM69lw2b1BZDOBbY9gp_hT5-zHnkQsBSCZcG3sWi8p_JBLoBVSnLEXfRRJ-TF1QHGfwTx0niP9KUsVox9SLauNAS4Scklxcmcdb6y5gyac1ExGii&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Below are the first mistakes I made during the application process to those universities :&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;My final course transcripts: Instead of applying with all my transcripts illustrating all the courses I studied in my undergrad, I used the transcript for my two last years at University. I later discovered that I should have used all my transcripts, and it was late to edit my application with those transcripts.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Since my degree did not have any equivalent in the UK educational system, I thought it was a master’s degree since I spent six years as an undergrad, but I was mistaken. I Should have called it as it was &lt;em&gt;Licence en Genie Electrique et Informatique&lt;/em&gt;. I finally asked the &lt;a href=&quot;https://academia.stackexchange.com/questions/166060/diploma-equivalence-from-the-old-belgian-system/166062#166062&quot;&gt;question on stack exchange&lt;/a&gt;, and I got the final answer.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;My statement of purpose: The statement of purpose is the letter that opens your doors to universities. While applying to this, mine was good, but it was not outstanding for a student with my experience. I did not illustrate how my undergrad studies and professional experience prepared me for the master.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;the-first-bach-outcome&quot;&gt;The first Bach outcome&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://lh4.googleusercontent.com/i0ZDVfj9GVCscjHgI3N9q_6nXKbswhHilgSg2UP8T7VB2VHDR0u2j4B8U62_29GxGYf1YNOv6ZmHp8SP-OFdUaImqKDDitUm0H1CcxWhKmyxeLG2ukmL2ytEG88zmBwBTstb3dXi&quot; /&gt;&lt;/p&gt;

&lt;p&gt;I got back-to-back rejections from those three universities, and the demons of Imposter Syndrome came back again.&lt;/p&gt;

&lt;p&gt;Those universities required students to have at least a 2:1 grade (first class or distinction and from good universities ), that was not my case.&lt;/p&gt;

&lt;p&gt;After failing to get admissions, start looking for middle-class university or Europa leagues teams for those familiar with Premier League.&lt;/p&gt;

&lt;h2 id=&quot;the-second-batch-of-applications&quot;&gt;The second batch of Applications&lt;/h2&gt;

&lt;p&gt;I came across the Data Science master at Cardiff, Data science at Sussex, Big Data and text Analytics at Essex, Data Science and AI at New Castle, and Artificial Intelligence at Leeds university. From my research, those were decent universities with good NLP courses in their curriculum and good researchers doing NLP.&lt;/p&gt;

&lt;h3 id=&quot;what-i-did-to-improve-my-applications&quot;&gt;What I did to improve my Applications&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;https://lh3.googleusercontent.com/Bs6HkG1xpJT1qpqtxl_yWv96rXTduSruS20mbneVlWhk6qJsuPoSEmnvOHImCTrE1lg6Q0r1fzG15qqtLalGeBRuVa_3hjFwWVdxjO3m4z7TJVmYElGIkPMlbhY1v3WqKpuAd7Vo&quot; /&gt;&lt;/p&gt;

&lt;p&gt;I started looking for graduates forums online to learn about the UK’s application process and stumbled across the &lt;a href=&quot;https://www.reddit.com/r/gradadmissions/&quot;&gt;grad admission subreddit&lt;/a&gt;, &lt;a href=&quot;https://www.reddit.com/r/gradadmissions/comments/9pd2b8/the_statement_of_purpose_prompt_for_ucsd_is_a/&quot;&gt;the statement of purpose subreddit.&lt;/a&gt; I found a fantastic &lt;a href=&quot;http://writeivy.com/structure-is-magic-a-guide-to-the-graduate-sop/&quot;&gt;guide&lt;/a&gt; on the subreddit written  by a graduate study expert, and I applied all the advice written in that blog. The statement of purpose subreddit has many students going in the same process as you and who are willing to help you review your SOP. I was glad I got help from the subreddit, and it helped me proofread my new statement.&lt;/p&gt;

&lt;p&gt;I went ahead and got all my transcripts from my university and translated them. I also got a letter confirming that I finished my studies at my university since we did not have our certificate signed by our Minister now. Don’t ask me why because I don’t have an answer for that.&lt;/p&gt;

&lt;p&gt;I applied to those universities with my updated transcripts, statements of purpose, and recommendation letters and started waiting for the results.&lt;/p&gt;

&lt;h3 id=&quot;the-second-batchs-outcome&quot;&gt;The second batch’s Outcome&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;https://lh4.googleusercontent.com/CU1lBE_xq9SWKo07bw3Z0ruD_usjutTMG3tci1Q0ewBBuZ5ZclIHj1R2DKAllST8wfNSnzqHzWYxiOvBgAgjwNLSaEVhEAM4XJhKv3uTEFe4wSoU1GGY6IWf5MnIaG27BTNiIBAF&quot; /&gt;&lt;/p&gt;

&lt;p&gt;I got another rejection from Leeds. But, to my dismay, in April, I got an Unconditional offer from Essex. The offer was enough to put me in an excellent position to get the Chevening scholarship. I submitted it as my second choice to Chevening with Cardiff, and Edinburgh being my 1st and third choices.&lt;/p&gt;

&lt;p&gt;I later received another offer from Sussex, New Castle, and a conditional offer from the Data Science program at Cardiff University.&lt;/p&gt;

&lt;p&gt;By the time I got the offer from those universities, I had already passed the Chevening Interview, and I could not amend my choices. Should I have got a chance to do so, I could have picked Sussex as my first choice and Cardiff as my third choice.&lt;/p&gt;

&lt;h2 id=&quot;the-final-decision&quot;&gt;The Final Decision&lt;/h2&gt;

&lt;p&gt;No matter how many offers I got, I had to attend only one university.&lt;/p&gt;

&lt;h3 id=&quot;why-sussex&quot;&gt;Why Sussex?&lt;/h3&gt;

&lt;p&gt;I found the master of Data Science at Susses a perfect choice for me and my career goals and NLP ambitions. The course has two NLP modules in the curriculum and has some good professors doing NLP research. It was near Brighton on the beach and had a good reputation for African students. And while applying for the university, I found that it has my local African university in its choices.&lt;/p&gt;

&lt;h3 id=&quot;why-cardiff-at-third&quot;&gt;Why Cardiff At third&lt;/h3&gt;

&lt;p&gt;Although their international department communication was good, I did not meet their condition in time to secure my scholarship. It required me to have my final degree signed by our minister on time but with our country’s politics that was not possible. There is the letter called &lt;em&gt;A qui de droit&lt;/em&gt;, which the university declined. After many back and forth with the grad admission team, I finally got an unconditional offer, but it was too late for the Chevening application deadline.&lt;/p&gt;

&lt;h3 id=&quot;so-i-ended-up-in-essex&quot;&gt;So I Ended up in Essex&lt;/h3&gt;

&lt;p&gt;Since it was the only university I submitted to Chevening after the interview, I got an offer. It was impossible to change it later, it was the only option I had, but if I had the choice to change, I could have chosen Sussex or Cardiff instead.&lt;/p&gt;

&lt;p&gt;I am not very happy with the university admission department, and they are somehow slowish. To illustrate that, we are one month before the course start date, but I haven’t yet got my Confirmation of Acceptance of Studies ( CAS). Anyway, it is already late to change my university choice. I will have to go there.&lt;/p&gt;

&lt;h2 id=&quot;what-i-am-looking-forward-to&quot;&gt;What I am looking forward to&lt;/h2&gt;

&lt;p&gt;I think the calm in the town will help me to concentrate on my studies. I am looking forward to interacting with Prof &lt;a href=&quot;https://www.essex.ac.uk/people/jamee22406/shoaib-jameel&quot;&gt;Dr. Shoaib Jameel&lt;/a&gt; and integrating his NLP group to research on great questions answering, search and information retrieval.&lt;/p&gt;

&lt;p&gt;Colchester seems to be a quiet city for me but  it is just one hour from London. I plan to enjoy my studies there and spend some weekends in London.&lt;/p&gt;

&lt;p&gt;I will enjoy my journey In the UK as much as possible and watch at least two premiers leagues games. The Manchester derby and a London derby.&lt;/p&gt;

&lt;h2 id=&quot;what-next-after-my-master&quot;&gt;What Next After My master&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://lh4.googleusercontent.com/xB8NvTHRCRnGLIBgb_hSJydGN4MG1lkY2ZC1IHW41UI0YNIOJ2lEervFw6KlgnThwtztOg3b6n7IibusYwo3I7BdXjVuPOLATkDWHTVwPwsdPPiqkTDzYizsB-T2urG3R5HAruly&quot; /&gt;&lt;/p&gt;

&lt;p&gt;What next After graduating, I will come back home and give back to the community. Yes, I will come back, my African people. I am not planning to stay in the UK; I will return to Africa; those are my ambitions. I hope to learn a lot during my studies and work hard for two years and see if I will still have the energy to apply for a Ph.D., this time in a top-four team.&lt;/p&gt;

&lt;h2 id=&quot;fears-reflections-and-joys&quot;&gt;Fears, Reflections, and Joys&lt;/h2&gt;

&lt;p&gt;The good news is that I got the Chevening scholarship, and I will be a sponsored student in the Uk for the following year. I have heard people congratulate me for that and tell me that it is a prestigious scholarship but let wait and see.&lt;/p&gt;

&lt;p&gt;I regret that I didn’t get admission from Edinburgh or Sheffield, which was kind of Europa League teams. I somehow regret the fact that I didn’t even apply to Oxbridge, University College London, or Imperial College London, like Man City, Man United, Liverpool, and Chelsea.&lt;/p&gt;

&lt;p&gt;My biggest fear is losing my job. I have a paying job that is paying me more than the monthly stipend Chevening gives. Will I be able to work part-time while studying? If not, how will I be able to support my family while studying?&lt;/p&gt;

&lt;p&gt;How will I get money to enjoy weekends in the UK, football matches, and meet beautiful girls?&lt;/p&gt;

&lt;p&gt;But sometimes I just sit down and say, it will be fine.&lt;/p&gt;

&lt;h2 id=&quot;lessons-learned&quot;&gt;Lessons learned&lt;/h2&gt;

&lt;p&gt;To sum up, here are the few lessons I learned:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;If you are in CS, this tool, &lt;a href=&quot;http://csrankings.org/#/index?nlp&amp;amp;ir&amp;amp;uk&quot;&gt;CSRankings: Computer Science Rankings&lt;/a&gt;, is a must-have you can use to learn more about university rankings. What I enjoyed about the website is that it doesn’t only give you university rankings. Still, it can rank university per topic or area and give you a list of professors working on a given topic. Those pieces of information are instrumental when you are writing your statement of purpose.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Join graduate communities on Reddit &lt;a href=&quot;https://www.reddit.com/r/gradadmissions/&quot;&gt;r/gradadminssion&lt;/a&gt;, &lt;a href=&quot;https://www.reddit.com/r/StatementOfPurpose/&quot;&gt;r/statement of purpose&lt;/a&gt;, and you will enjoy the help and resources you can find on those groups. I am not a fan of other social media platforms, but I am sure you can get more support and find similar groups to those subreddits.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;During the application time, most of the universities organize open days, virtual or on-site events. Make sure you attend those events and learn as much as you can about your department and the international admission department. This will help to put you in a good position when writing your statement of purpose and should put you in touch with the international admission team.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Make sure all your documents are ready on time. If you did not do your undergraduate in English, ensure you have certified translations of all your documents on time.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;If you are from a French university, start early to get an IELTS or TOEFL score on time,&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Make sure your recommendations are ready.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Never underestimate your contributions to community projects and the work you did back in university.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;And start applying early to learn as much as you can in the process.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;And to conclude, I will leave you with one of my favorite quotes:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://lh6.googleusercontent.com/DWzKbI2f7bbP_eCsfYXxShke33eQuW3zotTW_NlC1OJmA8EepOryVwKHSHn39N05-QX2xwjtKI8dpglgdYmorgICSvOCzg2WNK7liaJdF8m4ywfg2ct9wUwbyWqFvLI6c-6MHKob&quot; /&gt;&lt;/p&gt;

</description>
        <pubDate>Fri, 05 Nov 2021 23:00:36 +0000</pubDate>
        <link>http://localhost:4000/blog/2021/lessons-learned-while-applying-to-masters-degrees-in-the-uk/</link>
        <guid isPermaLink="true">http://localhost:4000/blog/2021/lessons-learned-while-applying-to-masters-degrees-in-the-uk/</guid>
        
        
        <category>non-tech</category>
        
      </item>
    
      <item>
        <title>How I break up with pip and fall in love with poetry my new girlfriend.</title>
        <description>&lt;p&gt;I have recently stumbled across &lt;a href=&quot;https://python-poetry.org/&quot;&gt;poetry&lt;/a&gt; new dependency management for python and decided to give it a try.&lt;/p&gt;

&lt;p&gt;I have been a die hard fan of pip and had used it in most of my projects before I discovered poetry. Furthermore, I had heard about pyenv in the past but was reluctant to use it in my projects for preference reasons. Since Python dependency management is an interesting topic, I would like to explain the difference in another article such as &lt;a href=&quot;https://github.com/pypa/pip&quot;&gt;pip&lt;/a&gt; vs &lt;a href=&quot;https://github.com/pyenv/pyenv&quot;&gt;pyenv&lt;/a&gt; vs &lt;a href=&quot;https://github.com/python-poetry/poetry&quot;&gt;petry&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;When I discovered poetry and tested it, I fell in love with it.&lt;/p&gt;

&lt;h2 id=&quot;what-is-poetry&quot;&gt;What is poetry?&lt;/h2&gt;

&lt;p&gt;Although I will be talking about girlfriends, falling in love , and breakups in this article, the poetry I am talking about is not about love, prose, poems, or Shakespeare.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Poetry is a tool for &lt;strong&gt;dependency management&lt;/strong&gt; and &lt;strong&gt;packaging&lt;/strong&gt; in Python. It allows you to declare the libraries your project depends on and it will manage (install/update) them for you.&lt;/em&gt; It supports Python 2.7 and 3.5+&lt;/p&gt;

&lt;p&gt;If you work with python and install packages you should be familiar with &lt;code class=&quot;language-clojure highlight highlighter-rouge&quot;&gt;&lt;span class=&quot;n&quot;&gt;pip&lt;/span&gt;&lt;/code&gt; my old girlfriend.&lt;/p&gt;

&lt;h2 id=&quot;why-we-should-use-poetry-in-lieu-of-pip&quot;&gt;Why we should use poetry in lieu of pip?&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://lh3.googleusercontent.com/WEae7StOBGmS6vkaiYroiIwEZWQ2c4DFa56RwhpuOLrzlJfMXlTfUxnpu299Xme-cRGZBdqA0HYUdVUQvduv3cwDSZHr8TMt6o4nwd4DmnWCRjco2xXlHndDSWn_rsQAPRM5saY=s0&quot; /&gt;&lt;/p&gt;

&lt;p&gt;After 2 weeks of usages and successful migration of five personal projects from &lt;code class=&quot;language-bash highlighter-rouge&quot;&gt;pip&lt;/code&gt; to &lt;code class=&quot;language-clojure highlight highlighter-rouge&quot;&gt;&lt;span class=&quot;n&quot;&gt;poetry&lt;/span&gt;&lt;/code&gt;, I can choose poetry because :&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;It has a good dependency resolver. It does the job better than PIP. Read the interesting article &lt;a href=&quot;https://www.activestate.com/resources/quick-reads/python-dependencies-everything-you-need-to-know/&quot;&gt;www.activestate.com&lt;/a&gt;. The author explicitly said&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;Unfortunately, pip makes no attempt to resolve dependency conflicts. For example, if you install two packages, package A may require a different version of a dependency than package B requires.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;And another advantage I found is that anytime you add a new dependency to the project poetry update for you the &lt;code class=&quot;language-bash highlighter-rouge&quot;&gt;pyproject.toml&lt;/code&gt; with the new top-level dependency, it, therefore, avoid you to do &lt;code class=&quot;language-clojure highlight highlighter-rouge&quot;&gt;&lt;span class=&quot;n&quot;&gt;pip&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;freeze&lt;/span&gt;&lt;/code&gt; to generate a new requirement file for your project.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;You can use the same tool to build and publish your packages.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;In my opinion, I think &lt;code class=&quot;language-bash highlighter-rouge&quot;&gt;poetry&lt;/code&gt; outweigh &lt;code class=&quot;language-clojure highlight highlighter-rouge&quot;&gt;&lt;span class=&quot;n&quot;&gt;pip&lt;/span&gt;&lt;/code&gt; in many aspects. It is like pip but on steroids&lt;/p&gt;

&lt;p&gt;In the following sections, I will guide you on how to migrate an existing project from pip to poetry.&lt;/p&gt;

&lt;h2 id=&quot;installing-poetry-in-your-system&quot;&gt;Installing Poetry in your system&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://lh5.googleusercontent.com/prDFZYFCdhOvTIpSpv8fItqiZ3GHrHEypuEhY0J2IyORNHoOwd6JlneUEUEGlcE-yRR0xVGkOUlwIeDWc5DfSCMrpJqX5m_CQxcERZ2fUzLmmOeV-dF-OYUbMAAg0t0uvxhAN-o=s0&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Installing poetry is very straightforward, if you have python installed and &lt;code class=&quot;language-clojure highlight highlighter-rouge&quot;&gt;&lt;span class=&quot;n&quot;&gt;curl&lt;/span&gt;&lt;/code&gt; you can easily install it by running :&lt;/p&gt;

&lt;h4 id=&quot;osx--linux--bashonwindows-install-instructions&quot;&gt;osx / linux / bashonwindows install instructions&lt;/h4&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;
curl &lt;span class=&quot;nt&quot;&gt;-sSL&lt;/span&gt; https://raw.githubusercontent.com/python-poetry/poetry/master/get-poetry.py | python -

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;windows-powershell-install-instructions&quot;&gt;windows powershell install instructions&lt;/h3&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;
&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;Invoke-WebRequest &lt;span class=&quot;nt&quot;&gt;-Uri&lt;/span&gt; https://raw.githubusercontent.com/python-poetry/poetry/master/install-poetry.py &lt;span class=&quot;nt&quot;&gt;-UseBasicParsing&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;.Content | python -

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Warning&lt;/strong&gt;: The previous &lt;code class=&quot;language-bash highlighter-rouge&quot;&gt;get-poetry.py&lt;/code&gt; installer is now deprecated, if you are currently using it you should migrate to the new, supported, &lt;code class=&quot;language-clojure highlight highlighter-rouge&quot;&gt;&lt;span class=&quot;n&quot;&gt;install-poetry.py&lt;/span&gt;&lt;/code&gt; installer.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;The installer installs the &lt;code class=&quot;language-bash highlighter-rouge&quot;&gt;poetry&lt;/code&gt; tool to Poetry’s &lt;code class=&quot;language-clojure highlight highlighter-rouge&quot;&gt;&lt;span class=&quot;n&quot;&gt;bin&lt;/span&gt;&lt;/code&gt; directory. This location depends on your system:&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code class=&quot;language-clojure highlight highlighter-rouge&quot;&gt;&lt;span class=&quot;n&quot;&gt;$HOME/.local/bin&lt;/span&gt;&lt;/code&gt; for Unix&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code class=&quot;language-clojure highlight highlighter-rouge&quot;&gt;&lt;span class=&quot;n&quot;&gt;%APPDATA%&lt;/span&gt;&lt;span class=&quot;sc&quot;&gt;\P&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ython&lt;/span&gt;&lt;span class=&quot;sc&quot;&gt;\S&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cripts&lt;/span&gt;&lt;/code&gt; on Windows&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;If this directory is not on your &lt;code class=&quot;language-bash highlighter-rouge&quot;&gt;PATH&lt;/code&gt;, you will need to add it manually if you want to invoke Poetry with simply &lt;code class=&quot;language-clojure highlight highlighter-rouge&quot;&gt;&lt;span class=&quot;n&quot;&gt;poetry&lt;/span&gt;&lt;/code&gt;.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;Alternatively, you can use the full path to &lt;code class=&quot;language-clojure highlight highlighter-rouge&quot;&gt;&lt;span class=&quot;n&quot;&gt;poetry&lt;/span&gt;&lt;/code&gt; to use it.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;There is also another version of installing it with &lt;code class=&quot;language-clojure highlight highlighter-rouge&quot;&gt;&lt;span class=&quot;n&quot;&gt;pip&lt;/span&gt;&lt;/code&gt; but why would you use your ex to attract your new girlfriend? 🤔🤪&lt;/p&gt;

&lt;p&gt;Once everything is installed you can restart your terminal and run the following command to check the poetry version:&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;language-clojure highlight highlighter-rouge&quot;&gt;&lt;span class=&quot;n&quot;&gt;poetry&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;--version&lt;/span&gt;&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;If installation is unsuccessfully or encountering incompatibility issues. Please heads up to &lt;a href=&quot;https://github.com/python-poetry/poetry&quot;&gt;Github Poetry&lt;/a&gt; to get a help, to learn more or to fire an issue.&lt;/p&gt;

&lt;h2 id=&quot;the-migration&quot;&gt;The Migration&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://lh4.googleusercontent.com/S09PZBBBn_Q9Vx8vpxLNP67_9HmU-JEM50KpnZZaZavhqS3y2tzfDFuvHlL59CJo_UKhtRtYyWofhx5zlUtvUbk3yO5HHsMM4rqs6xH0fCKaGWZsjlBX7T3j_R0WdPjvf1gG3U0=s0&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;generate-top-level-dependencies&quot;&gt;Generate top-level dependencies&lt;/h3&gt;

&lt;p&gt;Before moving to the next step you need to make sure you can generate the top-level dependencies for your project, to do that you will need a package called &lt;a href=&quot;https://pypi.org/project/pipdeptree/&quot;&gt;pipdeptree&lt;/a&gt; . For context, the top-level dependencies are the root of your dependencies tree. What is even the dependency tree? Each package you install using &lt;code class=&quot;language-bash highlighter-rouge&quot;&gt;pip&lt;/code&gt; has the other dependencies that rely on it. And before installing a new package it installs his top-level dependencies. For example, pandas is a package but &lt;code class=&quot;language-bash highlighter-rouge&quot;&gt;pandas&lt;/code&gt; depends on &lt;code class=&quot;language-clojure highlight highlighter-rouge&quot;&gt;&lt;span class=&quot;n&quot;&gt;numpy&lt;/span&gt;&lt;/code&gt;, if you install pandas it install also numpy as a dependent.&lt;/p&gt;

&lt;p&gt;The following command will generate only the top-level dependencies, so if you have installed pandas, it will just generate pandas and not numpy as a requirement.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Why is this important? :&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;This should be filled&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;language-clojure highlight highlighter-rouge&quot;&gt;&lt;span class=&quot;n&quot;&gt;pipdeptree&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;--warn&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;silence&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;err&quot;&gt;|&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;grep&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;-E&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;'^&lt;/span&gt;&lt;span class=&quot;sc&quot;&gt;\w&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;requirements-new.txt&lt;/span&gt;&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;Once you have generated the top-level dependencies, I would suggest you deactivate your virtual environment and delete it to make the break-up complete before moving to the next steps.&lt;/p&gt;

&lt;h3 id=&quot;adding-poetry-to-an-existing-project&quot;&gt;Adding poetry to an existing project.&lt;/h3&gt;

&lt;p&gt;If you have a new project where you are using &lt;code class=&quot;language-bash highlighter-rouge&quot;&gt;pip&lt;/code&gt; and have the &lt;code class=&quot;language-clojure highlight highlighter-rouge&quot;&gt;&lt;span class=&quot;n&quot;&gt;requirements.txt&lt;/span&gt;&lt;/code&gt; file inside you can run the following command to initialize poetry in the project.&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;language-clojure highlight highlighter-rouge&quot;&gt;&lt;span class=&quot;n&quot;&gt;poetry&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;init&lt;/span&gt;&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;This will prompt you to set up poetry to your existing project and asked you to give some details about your project such as the project name, the python version you want to use, and the description. It will consequently generate the &lt;code class=&quot;language-clojure highlight highlighter-rouge&quot;&gt;&lt;span class=&quot;n&quot;&gt;pyproject.toml&lt;/span&gt;&lt;/code&gt; file which will contain all the details about your project as well as the top-level projects requirement and their versions.&lt;/p&gt;

&lt;h3 id=&quot;creating-virtual-environment&quot;&gt;Creating virtual environment&lt;/h3&gt;

&lt;p&gt;Poetry creates by default virtual environment in a folder called &lt;code class=&quot;language-clojure highlight highlighter-rouge&quot;&gt;&lt;span class=&quot;o&quot;&gt;~&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;/Library/Application&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Support/pypoetry&lt;/span&gt;&lt;/code&gt; but you can change those settings by using the following command :&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;language-clojure highlight highlighter-rouge&quot;&gt;&lt;span class=&quot;n&quot;&gt;poetry&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;config&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;virtualenvs.in-project&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;true&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;After running that command you can run the following :&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;language-clojure highlight highlighter-rouge&quot;&gt;&lt;span class=&quot;n&quot;&gt;poetry&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shell&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;It will activate the project’s virtual environment and create a new one if the project does not have one.&lt;/p&gt;

&lt;h3 id=&quot;installing-the-requirements-for-your-projects&quot;&gt;Installing the requirements for your projects.&lt;/h3&gt;

&lt;p&gt;If you have the &lt;code class=&quot;language-clojure highlight highlighter-rouge&quot;&gt;&lt;span class=&quot;n&quot;&gt;requirements-news.txt&lt;/span&gt;&lt;/code&gt; file resulting from the command you run on the first step, you can install all the packages in that and their corresponding version by running the following command:&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;language-clojure highlight highlighter-rouge&quot;&gt;&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;in&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sed&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;-n&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;ss&quot;&gt;'s/==/&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;@&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;/p&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;requirements-new.txt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;; do poetry add &quot;${item}&quot; ; done&lt;/span&gt;&lt;/code&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;This will work only on Linux and Mac, still trying to find the exact version of it for Windows.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;What does that command do?
I loop over every line of the &lt;code class=&quot;language-bash highlighter-rouge&quot;&gt;requirement-new.txt&lt;/code&gt; file take the dependency, and just replace the &lt;code class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;span class=&quot;o&quot;&gt;==&lt;/span&gt;&lt;/code&gt; in the dependency with &lt;code class=&quot;language-clojure highlight highlighter-rouge&quot;&gt;&lt;span class=&quot;o&quot;&gt;@&lt;/span&gt;&lt;/code&gt; and then add it with poetry.&lt;/p&gt;

&lt;p&gt;If for example in the file you have pandas==1.1.1, it will install the following with poetry &lt;code class=&quot;language-clojure highlight highlighter-rouge&quot;&gt;&lt;span class=&quot;n&quot;&gt;poetry&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pandas&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;@&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;1.11&lt;/span&gt;&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;If everything goes well you should have the all the top-level packages installed with their dependencies.&lt;/p&gt;

&lt;p&gt;Once the command has successfully run and you have everything installed, you should check if your &lt;code class=&quot;language-clojure highlight highlighter-rouge&quot;&gt;&lt;span class=&quot;n&quot;&gt;pyproject.toml&lt;/span&gt;&lt;/code&gt; file contains all the packages and their top-level dependencies.&lt;/p&gt;

&lt;p&gt;You can now remove the old &lt;code class=&quot;language-bash highlighter-rouge&quot;&gt;requirements.txt&lt;/code&gt; file and the newly create &lt;code class=&quot;language-clojure highlight highlighter-rouge&quot;&gt;&lt;span class=&quot;n&quot;&gt;requirement-new.txt&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;/code&gt;file by running.&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;language-clojure highlight highlighter-rouge&quot;&gt;&lt;span class=&quot;n&quot;&gt;rm&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;-f&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;requirements.*&lt;/span&gt;&lt;/code&gt;&lt;/p&gt;

&lt;h3 id=&quot;a-section-about-using-poetry-with-conda-enviroment&quot;&gt;A section about using poetry with conda enviroment&lt;/h3&gt;

&lt;p&gt;Some people like to have multiples girlfriend and may like to keep their old conda or pip environment. I haven’t tried this approach yet , but according to&lt;a href=&quot;https://github.com/python-poetry/poetry/issues/105#issuecomment-498042062&quot;&gt; this issue&lt;/a&gt; it is possible to use poetry to install packages in a python environment.&lt;/p&gt;

&lt;p&gt;You just have to configure poetry to not create a virtual environment in a project and install your packages in the conda  or pip environment.&lt;/p&gt;

&lt;p&gt;I think you can try it and let us know in comment how it goes.&lt;/p&gt;

&lt;h3 id=&quot;bonus-the-dockerfile&quot;&gt;Bonus, the Dockerfile.&lt;/h3&gt;

&lt;p&gt;If you have a dockerfile you can edit it and use the following docker images which use multi-stage build to install all your requirement with poetry.&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;FROM python:3.7.5 AS base
LABEL &lt;span class=&quot;nv&quot;&gt;maintainer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Espoir Murhabazi &amp;lt; first_name.second_name[:3] on gmail.com&amp;gt;&quot;&lt;/span&gt;

ENV  &lt;span class=&quot;nv&quot;&gt;PYTHONUNBUFFERED&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;1  &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nv&quot;&gt;PYTHONDONTWRITEBYTECODE&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;1  &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nv&quot;&gt;PIP_NO_CACHE_DIR&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;off  &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nv&quot;&gt;PIP_DISABLE_PIP_VERSION_CHECK&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;on  &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nv&quot;&gt;PIP_DEFAULT_TIMEOUT&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;100  &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nv&quot;&gt;POETRY_HOME&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;/opt/poetry&quot;&lt;/span&gt;  &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nv&quot;&gt;POETRY_VIRTUALENVS_IN_PROJECT&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;true&lt;/span&gt;  &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nv&quot;&gt;POETRY_NO_INTERACTION&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;1  &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nv&quot;&gt;PYSETUP_PATH&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;/opt/pysetup&quot;&lt;/span&gt;  &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nv&quot;&gt;VENV_PATH&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;/opt/pysetup/.venv&quot;&lt;/span&gt;

ENV  &lt;span class=&quot;nv&quot;&gt;PATH&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$POETRY_HOME&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;/bin:&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$VENV_PATH&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;/bin:&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$PATH&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;

FROM  base  AS  python-deps

RUN  apt-get  update  &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;

&lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt;  apt-get  &lt;span class=&quot;nb&quot;&gt;install&lt;/span&gt;  &lt;span class=&quot;nt&quot;&gt;--no-install-recommends&lt;/span&gt;  &lt;span class=&quot;nt&quot;&gt;-y&lt;/span&gt;  &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;

curl  &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;

build-essential
&lt;span class=&quot;c&quot;&gt;# Install Poetry - respects $POETRY_VERSION &amp;amp; $POETRY_HOME&lt;/span&gt;
ENV &lt;span class=&quot;nv&quot;&gt;POETRY_VERSION&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;1.1.7

RUN curl &lt;span class=&quot;nt&quot;&gt;-sSL&lt;/span&gt; https://raw.githubusercontent.com/sdispater/poetry/master/get-poetry.py | python
WORKDIR &lt;span class=&quot;nv&quot;&gt;$PYSETUP_PATH&lt;/span&gt;

COPY ./poetry.lock ./pyproject.toml ./
RUN poetry &lt;span class=&quot;nb&quot;&gt;install&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;--no-dev&lt;/span&gt;
FROM base AS runtime
COPY &lt;span class=&quot;nt&quot;&gt;--from&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;python-deps &lt;span class=&quot;nv&quot;&gt;$POETRY_HOME&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;$POETRY_HOME&lt;/span&gt;
COPY &lt;span class=&quot;nt&quot;&gt;--from&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;python-deps &lt;span class=&quot;nv&quot;&gt;$PYSETUP_PATH&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;$PYSETUP_PATH&lt;/span&gt;
RUN useradd &lt;span class=&quot;nt&quot;&gt;-ms&lt;/span&gt; /bin/bash espy
COPY &lt;span class=&quot;nb&quot;&gt;.&lt;/span&gt; /home/espy
WORKDIR /home/espy
USER espy
CMD &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot; you command &quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Basically, what the docker file does, it uses a multi-stage build to first install the packages in the first step and copy only the packages installed in the second as well as the project repository. One of the advantages of the multi-stage build is that it uses only the necessary files your project needs and therefore reduce the memory of your docker container.&lt;/p&gt;

&lt;p&gt;You can learn more about multi-stage build using the &lt;a href=&quot;[https://pythonspeed.com/articles/multi-stage-docker-python/](https://pythonspeed.com/articles/multi-stage-docker-python/)&quot;&gt;following tutorial.&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;And the story of my break up comes to an end. As you may know, all separations are not smooth, sometimes the daemons of your old girlfriend come and start causing troubles in your new relationship. So if you find any issue during this break-up, feel free to let me know in the comment I will try to help you as much as I can 🤔.&lt;/p&gt;
</description>
        <pubDate>Sun, 17 Oct 2021 16:33:42 +0100</pubDate>
        <link>http://localhost:4000/blog/2021/how-i-break-up-with-pip-and-fall-in-love-with-poetry-my-new-girlfriend/</link>
        <guid isPermaLink="true">http://localhost:4000/blog/2021/how-i-break-up-with-pip-and-fall-in-love-with-poetry-my-new-girlfriend/</guid>
        
        
        <category>tech</category>
        
      </item>
    
  </channel>
</rss>
